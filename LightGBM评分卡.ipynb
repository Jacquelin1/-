{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_mth</th>\n",
       "      <th>bad_ind</th>\n",
       "      <th>uid</th>\n",
       "      <th>td_score</th>\n",
       "      <th>jxl_score</th>\n",
       "      <th>mj_score</th>\n",
       "      <th>rh_score</th>\n",
       "      <th>zzc_score</th>\n",
       "      <th>zcx_score</th>\n",
       "      <th>person_info</th>\n",
       "      <th>finance_info</th>\n",
       "      <th>credit_info</th>\n",
       "      <th>act_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A10000005</td>\n",
       "      <td>0.675349</td>\n",
       "      <td>0.144072</td>\n",
       "      <td>0.186899</td>\n",
       "      <td>0.483640</td>\n",
       "      <td>0.928328</td>\n",
       "      <td>0.369644</td>\n",
       "      <td>-0.322581</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.217949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A1000002</td>\n",
       "      <td>0.825269</td>\n",
       "      <td>0.398688</td>\n",
       "      <td>0.139396</td>\n",
       "      <td>0.843725</td>\n",
       "      <td>0.605194</td>\n",
       "      <td>0.406122</td>\n",
       "      <td>-0.128677</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A1000011</td>\n",
       "      <td>0.315406</td>\n",
       "      <td>0.629745</td>\n",
       "      <td>0.535854</td>\n",
       "      <td>0.197392</td>\n",
       "      <td>0.614416</td>\n",
       "      <td>0.320731</td>\n",
       "      <td>0.062660</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.448718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A10000481</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.609360</td>\n",
       "      <td>0.366081</td>\n",
       "      <td>0.342243</td>\n",
       "      <td>0.870006</td>\n",
       "      <td>0.288692</td>\n",
       "      <td>0.078853</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.179487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A1000069</td>\n",
       "      <td>0.406310</td>\n",
       "      <td>0.405352</td>\n",
       "      <td>0.783015</td>\n",
       "      <td>0.563953</td>\n",
       "      <td>0.715454</td>\n",
       "      <td>0.512554</td>\n",
       "      <td>-0.261014</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      obs_mth  bad_ind        uid  td_score  jxl_score  mj_score  rh_score  \\\n",
       "0  2018-10-31      0.0  A10000005  0.675349   0.144072  0.186899  0.483640   \n",
       "1  2018-07-31      0.0   A1000002  0.825269   0.398688  0.139396  0.843725   \n",
       "2  2018-09-30      0.0   A1000011  0.315406   0.629745  0.535854  0.197392   \n",
       "3  2018-07-31      0.0  A10000481  0.002386   0.609360  0.366081  0.342243   \n",
       "4  2018-07-31      0.0   A1000069  0.406310   0.405352  0.783015  0.563953   \n",
       "\n",
       "   zzc_score  zcx_score  person_info  finance_info  credit_info  act_info  \n",
       "0   0.928328   0.369644    -0.322581      0.023810         0.00  0.217949  \n",
       "1   0.605194   0.406122    -0.128677      0.023810         0.00  0.423077  \n",
       "2   0.614416   0.320731     0.062660      0.023810         0.10  0.448718  \n",
       "3   0.870006   0.288692     0.078853      0.071429         0.05  0.179487  \n",
       "4   0.715454   0.512554    -0.261014      0.023810         0.00  0.423077  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'/Users/jacquelin/Documents/python/金融风控实战/Bcard.txt')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95806, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2018-10-31', '2018-07-31', '2018-09-30', '2018-06-30',\n",
       "       '2018-11-30'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#看一下月份分布，我们用最后一个月做为跨时间验证集合\n",
    "data.obs_mth.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data[data.obs_mth != '2018-11-30'].reset_index().copy()\n",
    "val = data[data.obs_mth == '2018-11-30'].reset_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这是我们全部的变量，info结尾的是自己做的无监督系统输出的个人表现，score结尾的是收费的外部征信数据\n",
    "lst = ['person_info','finance_info','credit_info','act_info','td_score','jxl_score','mj_score','rh_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>obs_mth</th>\n",
       "      <th>bad_ind</th>\n",
       "      <th>uid</th>\n",
       "      <th>td_score</th>\n",
       "      <th>jxl_score</th>\n",
       "      <th>mj_score</th>\n",
       "      <th>rh_score</th>\n",
       "      <th>zzc_score</th>\n",
       "      <th>zcx_score</th>\n",
       "      <th>person_info</th>\n",
       "      <th>finance_info</th>\n",
       "      <th>credit_info</th>\n",
       "      <th>act_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A10000005</td>\n",
       "      <td>0.675349</td>\n",
       "      <td>0.144072</td>\n",
       "      <td>0.186899</td>\n",
       "      <td>0.483640</td>\n",
       "      <td>0.928328</td>\n",
       "      <td>0.369644</td>\n",
       "      <td>-0.322581</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.217949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A1000002</td>\n",
       "      <td>0.825269</td>\n",
       "      <td>0.398688</td>\n",
       "      <td>0.139396</td>\n",
       "      <td>0.843725</td>\n",
       "      <td>0.605194</td>\n",
       "      <td>0.406122</td>\n",
       "      <td>-0.128677</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A1000011</td>\n",
       "      <td>0.315406</td>\n",
       "      <td>0.629745</td>\n",
       "      <td>0.535854</td>\n",
       "      <td>0.197392</td>\n",
       "      <td>0.614416</td>\n",
       "      <td>0.320731</td>\n",
       "      <td>0.062660</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.448718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A10000481</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.609360</td>\n",
       "      <td>0.366081</td>\n",
       "      <td>0.342243</td>\n",
       "      <td>0.870006</td>\n",
       "      <td>0.288692</td>\n",
       "      <td>0.078853</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.179487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A1000069</td>\n",
       "      <td>0.406310</td>\n",
       "      <td>0.405352</td>\n",
       "      <td>0.783015</td>\n",
       "      <td>0.563953</td>\n",
       "      <td>0.715454</td>\n",
       "      <td>0.512554</td>\n",
       "      <td>-0.261014</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     obs_mth  bad_ind        uid  td_score  jxl_score  mj_score  \\\n",
       "0      0  2018-10-31      0.0  A10000005  0.675349   0.144072  0.186899   \n",
       "1      1  2018-07-31      0.0   A1000002  0.825269   0.398688  0.139396   \n",
       "2      2  2018-09-30      0.0   A1000011  0.315406   0.629745  0.535854   \n",
       "3      3  2018-07-31      0.0  A10000481  0.002386   0.609360  0.366081   \n",
       "4      4  2018-07-31      0.0   A1000069  0.406310   0.405352  0.783015   \n",
       "\n",
       "   rh_score  zzc_score  zcx_score  person_info  finance_info  credit_info  \\\n",
       "0  0.483640   0.928328   0.369644    -0.322581      0.023810         0.00   \n",
       "1  0.843725   0.605194   0.406122    -0.128677      0.023810         0.00   \n",
       "2  0.197392   0.614416   0.320731     0.062660      0.023810         0.10   \n",
       "3  0.342243   0.870006   0.288692     0.078853      0.071429         0.05   \n",
       "4  0.563953   0.715454   0.512554    -0.261014      0.023810         0.00   \n",
       "\n",
       "   act_info  \n",
       "0  0.217949  \n",
       "1  0.423077  \n",
       "2  0.448718  \n",
       "3  0.179487  \n",
       "4  0.423077  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train = df_train.sort_values(by = 'obs_mth',ascending = False)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>obs_mth</th>\n",
       "      <th>bad_ind</th>\n",
       "      <th>uid</th>\n",
       "      <th>td_score</th>\n",
       "      <th>jxl_score</th>\n",
       "      <th>mj_score</th>\n",
       "      <th>rh_score</th>\n",
       "      <th>zzc_score</th>\n",
       "      <th>zcx_score</th>\n",
       "      <th>person_info</th>\n",
       "      <th>finance_info</th>\n",
       "      <th>credit_info</th>\n",
       "      <th>act_info</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A10000005</td>\n",
       "      <td>0.675349</td>\n",
       "      <td>0.144072</td>\n",
       "      <td>0.186899</td>\n",
       "      <td>0.483640</td>\n",
       "      <td>0.928328</td>\n",
       "      <td>0.369644</td>\n",
       "      <td>-0.322581</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.217949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33407</th>\n",
       "      <td>33407</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2810176</td>\n",
       "      <td>0.146055</td>\n",
       "      <td>0.079922</td>\n",
       "      <td>0.250568</td>\n",
       "      <td>0.045240</td>\n",
       "      <td>0.766906</td>\n",
       "      <td>0.413713</td>\n",
       "      <td>0.013863</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33383</th>\n",
       "      <td>33383</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2807687</td>\n",
       "      <td>0.551366</td>\n",
       "      <td>0.300781</td>\n",
       "      <td>0.225007</td>\n",
       "      <td>0.045447</td>\n",
       "      <td>0.735733</td>\n",
       "      <td>0.684182</td>\n",
       "      <td>-0.261014</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33379</th>\n",
       "      <td>33379</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2807232</td>\n",
       "      <td>0.708547</td>\n",
       "      <td>0.769513</td>\n",
       "      <td>0.928457</td>\n",
       "      <td>0.739716</td>\n",
       "      <td>0.947453</td>\n",
       "      <td>0.361551</td>\n",
       "      <td>-0.128677</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33376</th>\n",
       "      <td>33376</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2806932</td>\n",
       "      <td>0.482248</td>\n",
       "      <td>0.116658</td>\n",
       "      <td>0.286273</td>\n",
       "      <td>0.056618</td>\n",
       "      <td>0.047024</td>\n",
       "      <td>0.890433</td>\n",
       "      <td>0.078853</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     obs_mth  bad_ind        uid  td_score  jxl_score  mj_score  \\\n",
       "0          0  2018-10-31      0.0  A10000005  0.675349   0.144072  0.186899   \n",
       "33407  33407  2018-10-31      0.0   A2810176  0.146055   0.079922  0.250568   \n",
       "33383  33383  2018-10-31      0.0   A2807687  0.551366   0.300781  0.225007   \n",
       "33379  33379  2018-10-31      0.0   A2807232  0.708547   0.769513  0.928457   \n",
       "33376  33376  2018-10-31      0.0   A2806932  0.482248   0.116658  0.286273   \n",
       "\n",
       "       rh_score  zzc_score  zcx_score  person_info  finance_info  credit_info  \\\n",
       "0      0.483640   0.928328   0.369644    -0.322581      0.023810         0.00   \n",
       "33407  0.045240   0.766906   0.413713     0.013863      0.023810         0.00   \n",
       "33383  0.045447   0.735733   0.684182    -0.261014      0.071429         0.03   \n",
       "33379  0.739716   0.947453   0.361551    -0.128677      0.047619         0.00   \n",
       "33376  0.056618   0.047024   0.890433     0.078853      0.047619         0.00   \n",
       "\n",
       "       act_info  rank  \n",
       "0      0.217949     1  \n",
       "33407  0.269231     1  \n",
       "33383  0.269231     1  \n",
       "33379  0.269231     1  \n",
       "33376  0.269231     1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.sort_values(by = 'obs_mth',ascending = False)\n",
    "\n",
    "rank_lst = []\n",
    "for i in range(1,len(df_train)+1):\n",
    "    rank_lst.append(i)\n",
    "    \n",
    "df_train['rank'] = rank_lst\n",
    "\n",
    "df_train['rank'] = df_train['rank']/len(df_train)\n",
    "\n",
    "pct_lst = []\n",
    "for x in df_train['rank']:\n",
    "    if x <= 0.2:\n",
    "        x = 1\n",
    "    elif x <= 0.4:\n",
    "        x = 2\n",
    "    elif x <= 0.6:\n",
    "        x = 3\n",
    "    elif x <= 0.8:\n",
    "        x = 4\n",
    "    else:\n",
    "        x = 5\n",
    "    pct_lst.append(x)\n",
    "df_train['rank'] = pct_lst        \n",
    "#train = train.drop('obs_mth',axis = 1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank\n",
       "1    15966\n",
       "2    15966\n",
       "3    15966\n",
       "4    15966\n",
       "5    15967\n",
       "Name: rank, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['rank'].groupby(df_train['rank']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bin_record = pd.DataFrame()\n",
    "for col in col_lst:\n",
    "    cb.pct_bin(data,col,'label')\n",
    "    cb.plot_woe()\n",
    "    data[col] = cb.trans_to_woe(data[col])\n",
    "    rcd = cb.get_bin_stats()\n",
    "    if bin_record.empty:\n",
    "        bin_record = rcd\n",
    "    else:\n",
    "        bin_record = bin_record.append(rcd)\n",
    "bin_record.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79831"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "print(set(df_train['rank']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义lgb函数\n",
    "def LGB_test(train_x,train_y,test_x,test_y):\n",
    "    from multiprocessing import cpu_count\n",
    "    clf = lgb.LGBMClassifier(\n",
    "        boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "        max_depth=2, n_estimators=80,max_features = 140, objective='binary',\n",
    "        subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "        learning_rate=0.05, min_child_weight=50,random_state=None,n_jobs=cpu_count()-1,\n",
    "        num_iterations = 80 #迭代次数\n",
    "    )\n",
    "    clf.fit(train_x, train_y,eval_set=[(train_x, train_y),(test_x,test_y)],eval_metric='auc',early_stopping_rounds=100)\n",
    "    print(clf.n_features_)\n",
    "\n",
    "    return clf,clf.best_score_[ 'valid_1']['auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacquelin/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.737137\ttraining's binary_logloss: 0.0832707\tvalid_1's auc: 0.712178\tvalid_1's binary_logloss: 0.12168\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.779956\ttraining's binary_logloss: 0.0821329\tvalid_1's auc: 0.773038\tvalid_1's binary_logloss: 0.119538\n",
      "[3]\ttraining's auc: 0.787657\ttraining's binary_logloss: 0.0816239\tvalid_1's auc: 0.759829\tvalid_1's binary_logloss: 0.118773\n",
      "[4]\ttraining's auc: 0.787083\ttraining's binary_logloss: 0.0811169\tvalid_1's auc: 0.758327\tvalid_1's binary_logloss: 0.117919\n",
      "[5]\ttraining's auc: 0.791363\ttraining's binary_logloss: 0.0803378\tvalid_1's auc: 0.768679\tvalid_1's binary_logloss: 0.116488\n",
      "[6]\ttraining's auc: 0.797614\ttraining's binary_logloss: 0.0796057\tvalid_1's auc: 0.779753\tvalid_1's binary_logloss: 0.11516\n",
      "[7]\ttraining's auc: 0.796785\ttraining's binary_logloss: 0.0792409\tvalid_1's auc: 0.779428\tvalid_1's binary_logloss: 0.114638\n",
      "[8]\ttraining's auc: 0.799178\ttraining's binary_logloss: 0.0786552\tvalid_1's auc: 0.779952\tvalid_1's binary_logloss: 0.1136\n",
      "[9]\ttraining's auc: 0.800233\ttraining's binary_logloss: 0.078141\tvalid_1's auc: 0.780585\tvalid_1's binary_logloss: 0.112795\n",
      "[10]\ttraining's auc: 0.800095\ttraining's binary_logloss: 0.0778623\tvalid_1's auc: 0.779255\tvalid_1's binary_logloss: 0.11246\n",
      "[11]\ttraining's auc: 0.800564\ttraining's binary_logloss: 0.0773838\tvalid_1's auc: 0.780632\tvalid_1's binary_logloss: 0.11162\n",
      "[12]\ttraining's auc: 0.801518\ttraining's binary_logloss: 0.0769709\tvalid_1's auc: 0.782005\tvalid_1's binary_logloss: 0.110988\n",
      "[13]\ttraining's auc: 0.799616\ttraining's binary_logloss: 0.076757\tvalid_1's auc: 0.779543\tvalid_1's binary_logloss: 0.110771\n",
      "[14]\ttraining's auc: 0.799979\ttraining's binary_logloss: 0.0764021\tvalid_1's auc: 0.780339\tvalid_1's binary_logloss: 0.110206\n",
      "[15]\ttraining's auc: 0.803135\ttraining's binary_logloss: 0.0760872\tvalid_1's auc: 0.782372\tvalid_1's binary_logloss: 0.109794\n",
      "[16]\ttraining's auc: 0.803352\ttraining's binary_logloss: 0.0758013\tvalid_1's auc: 0.783064\tvalid_1's binary_logloss: 0.109309\n",
      "[17]\ttraining's auc: 0.804747\ttraining's binary_logloss: 0.0755999\tvalid_1's auc: 0.783873\tvalid_1's binary_logloss: 0.109072\n",
      "[18]\ttraining's auc: 0.804488\ttraining's binary_logloss: 0.0753487\tvalid_1's auc: 0.784544\tvalid_1's binary_logloss: 0.108687\n",
      "[19]\ttraining's auc: 0.805255\ttraining's binary_logloss: 0.0751014\tvalid_1's auc: 0.784966\tvalid_1's binary_logloss: 0.10833\n",
      "[20]\ttraining's auc: 0.805515\ttraining's binary_logloss: 0.0749265\tvalid_1's auc: 0.784932\tvalid_1's binary_logloss: 0.108144\n",
      "[21]\ttraining's auc: 0.805492\ttraining's binary_logloss: 0.074729\tvalid_1's auc: 0.785172\tvalid_1's binary_logloss: 0.107857\n",
      "[22]\ttraining's auc: 0.806313\ttraining's binary_logloss: 0.0745607\tvalid_1's auc: 0.785839\tvalid_1's binary_logloss: 0.107622\n",
      "[23]\ttraining's auc: 0.806817\ttraining's binary_logloss: 0.074424\tvalid_1's auc: 0.785816\tvalid_1's binary_logloss: 0.107488\n",
      "[24]\ttraining's auc: 0.807193\ttraining's binary_logloss: 0.0742699\tvalid_1's auc: 0.78552\tvalid_1's binary_logloss: 0.107392\n",
      "[25]\ttraining's auc: 0.807639\ttraining's binary_logloss: 0.0741103\tvalid_1's auc: 0.785228\tvalid_1's binary_logloss: 0.10721\n",
      "[26]\ttraining's auc: 0.808227\ttraining's binary_logloss: 0.0739871\tvalid_1's auc: 0.784998\tvalid_1's binary_logloss: 0.107082\n",
      "[27]\ttraining's auc: 0.809528\ttraining's binary_logloss: 0.0738892\tvalid_1's auc: 0.784879\tvalid_1's binary_logloss: 0.106981\n",
      "[28]\ttraining's auc: 0.811116\ttraining's binary_logloss: 0.0737893\tvalid_1's auc: 0.786362\tvalid_1's binary_logloss: 0.106936\n",
      "[29]\ttraining's auc: 0.810897\ttraining's binary_logloss: 0.073679\tvalid_1's auc: 0.786837\tvalid_1's binary_logloss: 0.106795\n",
      "[30]\ttraining's auc: 0.811648\ttraining's binary_logloss: 0.0735682\tvalid_1's auc: 0.786791\tvalid_1's binary_logloss: 0.106699\n",
      "[31]\ttraining's auc: 0.811873\ttraining's binary_logloss: 0.0734598\tvalid_1's auc: 0.786316\tvalid_1's binary_logloss: 0.106619\n",
      "[32]\ttraining's auc: 0.811835\ttraining's binary_logloss: 0.0733832\tvalid_1's auc: 0.786031\tvalid_1's binary_logloss: 0.106599\n",
      "[33]\ttraining's auc: 0.811977\ttraining's binary_logloss: 0.073282\tvalid_1's auc: 0.786137\tvalid_1's binary_logloss: 0.106495\n",
      "[34]\ttraining's auc: 0.812127\ttraining's binary_logloss: 0.0732173\tvalid_1's auc: 0.785708\tvalid_1's binary_logloss: 0.106511\n",
      "[35]\ttraining's auc: 0.812001\ttraining's binary_logloss: 0.0731508\tvalid_1's auc: 0.785861\tvalid_1's binary_logloss: 0.106454\n",
      "[36]\ttraining's auc: 0.812269\ttraining's binary_logloss: 0.0730878\tvalid_1's auc: 0.785533\tvalid_1's binary_logloss: 0.106435\n",
      "[37]\ttraining's auc: 0.81302\ttraining's binary_logloss: 0.0730101\tvalid_1's auc: 0.784796\tvalid_1's binary_logloss: 0.106412\n",
      "[38]\ttraining's auc: 0.813302\ttraining's binary_logloss: 0.0729402\tvalid_1's auc: 0.784632\tvalid_1's binary_logloss: 0.106409\n",
      "[39]\ttraining's auc: 0.813896\ttraining's binary_logloss: 0.0728764\tvalid_1's auc: 0.784974\tvalid_1's binary_logloss: 0.106342\n",
      "[40]\ttraining's auc: 0.814032\ttraining's binary_logloss: 0.072824\tvalid_1's auc: 0.785171\tvalid_1's binary_logloss: 0.106288\n",
      "[41]\ttraining's auc: 0.814233\ttraining's binary_logloss: 0.0727596\tvalid_1's auc: 0.785623\tvalid_1's binary_logloss: 0.106237\n",
      "[42]\ttraining's auc: 0.814391\ttraining's binary_logloss: 0.0727135\tvalid_1's auc: 0.785634\tvalid_1's binary_logloss: 0.106207\n",
      "[43]\ttraining's auc: 0.814671\ttraining's binary_logloss: 0.0726635\tvalid_1's auc: 0.785777\tvalid_1's binary_logloss: 0.106172\n",
      "[44]\ttraining's auc: 0.814689\ttraining's binary_logloss: 0.0726168\tvalid_1's auc: 0.785387\tvalid_1's binary_logloss: 0.106188\n",
      "[45]\ttraining's auc: 0.814518\ttraining's binary_logloss: 0.0725737\tvalid_1's auc: 0.78547\tvalid_1's binary_logloss: 0.10613\n",
      "[46]\ttraining's auc: 0.814832\ttraining's binary_logloss: 0.0725258\tvalid_1's auc: 0.785709\tvalid_1's binary_logloss: 0.106099\n",
      "[47]\ttraining's auc: 0.815099\ttraining's binary_logloss: 0.0724814\tvalid_1's auc: 0.785959\tvalid_1's binary_logloss: 0.106053\n",
      "[48]\ttraining's auc: 0.815353\ttraining's binary_logloss: 0.0724374\tvalid_1's auc: 0.785874\tvalid_1's binary_logloss: 0.106026\n",
      "[49]\ttraining's auc: 0.81525\ttraining's binary_logloss: 0.0723973\tvalid_1's auc: 0.78591\tvalid_1's binary_logloss: 0.106027\n",
      "[50]\ttraining's auc: 0.815296\ttraining's binary_logloss: 0.0723627\tvalid_1's auc: 0.78581\tvalid_1's binary_logloss: 0.106005\n",
      "[51]\ttraining's auc: 0.815512\ttraining's binary_logloss: 0.0723276\tvalid_1's auc: 0.785415\tvalid_1's binary_logloss: 0.10604\n",
      "[52]\ttraining's auc: 0.815828\ttraining's binary_logloss: 0.0723091\tvalid_1's auc: 0.785942\tvalid_1's binary_logloss: 0.106002\n",
      "[53]\ttraining's auc: 0.8156\ttraining's binary_logloss: 0.072295\tvalid_1's auc: 0.785885\tvalid_1's binary_logloss: 0.105995\n",
      "[54]\ttraining's auc: 0.815635\ttraining's binary_logloss: 0.0722595\tvalid_1's auc: 0.785942\tvalid_1's binary_logloss: 0.10599\n",
      "[55]\ttraining's auc: 0.815678\ttraining's binary_logloss: 0.0722314\tvalid_1's auc: 0.785967\tvalid_1's binary_logloss: 0.106\n",
      "[56]\ttraining's auc: 0.815706\ttraining's binary_logloss: 0.0721984\tvalid_1's auc: 0.785853\tvalid_1's binary_logloss: 0.105979\n",
      "[57]\ttraining's auc: 0.816073\ttraining's binary_logloss: 0.0721753\tvalid_1's auc: 0.786098\tvalid_1's binary_logloss: 0.105963\n",
      "[58]\ttraining's auc: 0.8161\ttraining's binary_logloss: 0.0721507\tvalid_1's auc: 0.785843\tvalid_1's binary_logloss: 0.10596\n",
      "[59]\ttraining's auc: 0.816179\ttraining's binary_logloss: 0.0721195\tvalid_1's auc: 0.78596\tvalid_1's binary_logloss: 0.105927\n",
      "[60]\ttraining's auc: 0.816269\ttraining's binary_logloss: 0.072096\tvalid_1's auc: 0.786205\tvalid_1's binary_logloss: 0.105923\n",
      "[61]\ttraining's auc: 0.816416\ttraining's binary_logloss: 0.0720742\tvalid_1's auc: 0.786516\tvalid_1's binary_logloss: 0.105911\n",
      "[62]\ttraining's auc: 0.816535\ttraining's binary_logloss: 0.072049\tvalid_1's auc: 0.786509\tvalid_1's binary_logloss: 0.10592\n",
      "[63]\ttraining's auc: 0.816589\ttraining's binary_logloss: 0.072023\tvalid_1's auc: 0.786443\tvalid_1's binary_logloss: 0.10595\n",
      "[64]\ttraining's auc: 0.816668\ttraining's binary_logloss: 0.072005\tvalid_1's auc: 0.786688\tvalid_1's binary_logloss: 0.105935\n",
      "[65]\ttraining's auc: 0.816827\ttraining's binary_logloss: 0.071983\tvalid_1's auc: 0.786675\tvalid_1's binary_logloss: 0.105958\n",
      "[66]\ttraining's auc: 0.816955\ttraining's binary_logloss: 0.0719667\tvalid_1's auc: 0.786444\tvalid_1's binary_logloss: 0.105989\n",
      "[67]\ttraining's auc: 0.817083\ttraining's binary_logloss: 0.0719441\tvalid_1's auc: 0.785922\tvalid_1's binary_logloss: 0.106031\n",
      "[68]\ttraining's auc: 0.817243\ttraining's binary_logloss: 0.0719268\tvalid_1's auc: 0.785906\tvalid_1's binary_logloss: 0.106044\n",
      "[69]\ttraining's auc: 0.817256\ttraining's binary_logloss: 0.0719066\tvalid_1's auc: 0.785847\tvalid_1's binary_logloss: 0.106065\n",
      "[70]\ttraining's auc: 0.817406\ttraining's binary_logloss: 0.071888\tvalid_1's auc: 0.785889\tvalid_1's binary_logloss: 0.106065\n",
      "[71]\ttraining's auc: 0.817542\ttraining's binary_logloss: 0.0718725\tvalid_1's auc: 0.785982\tvalid_1's binary_logloss: 0.106052\n",
      "[72]\ttraining's auc: 0.81753\ttraining's binary_logloss: 0.0718579\tvalid_1's auc: 0.785898\tvalid_1's binary_logloss: 0.10607\n",
      "[73]\ttraining's auc: 0.817572\ttraining's binary_logloss: 0.0718444\tvalid_1's auc: 0.785999\tvalid_1's binary_logloss: 0.106067\n",
      "[74]\ttraining's auc: 0.8177\ttraining's binary_logloss: 0.0718338\tvalid_1's auc: 0.786248\tvalid_1's binary_logloss: 0.106055\n",
      "[75]\ttraining's auc: 0.817776\ttraining's binary_logloss: 0.0718139\tvalid_1's auc: 0.786254\tvalid_1's binary_logloss: 0.10606\n",
      "[76]\ttraining's auc: 0.817746\ttraining's binary_logloss: 0.0717932\tvalid_1's auc: 0.786234\tvalid_1's binary_logloss: 0.106069\n",
      "[77]\ttraining's auc: 0.817805\ttraining's binary_logloss: 0.0717813\tvalid_1's auc: 0.786385\tvalid_1's binary_logloss: 0.106051\n",
      "[78]\ttraining's auc: 0.81785\ttraining's binary_logloss: 0.0717608\tvalid_1's auc: 0.786448\tvalid_1's binary_logloss: 0.106048\n",
      "[79]\ttraining's auc: 0.817856\ttraining's binary_logloss: 0.0717497\tvalid_1's auc: 0.786389\tvalid_1's binary_logloss: 0.106043\n",
      "[80]\ttraining's auc: 0.817805\ttraining's binary_logloss: 0.0717335\tvalid_1's auc: 0.78636\tvalid_1's binary_logloss: 0.106046\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[79]\ttraining's auc: 0.817856\ttraining's binary_logloss: 0.0717497\tvalid_1's auc: 0.786389\tvalid_1's binary_logloss: 0.106043\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.741457\ttraining's binary_logloss: 0.0863868\tvalid_1's auc: 0.713623\tvalid_1's binary_logloss: 0.109309\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.78475\ttraining's binary_logloss: 0.0852072\tvalid_1's auc: 0.771443\tvalid_1's binary_logloss: 0.107672\n",
      "[3]\ttraining's auc: 0.789005\ttraining's binary_logloss: 0.0846673\tvalid_1's auc: 0.773894\tvalid_1's binary_logloss: 0.107001\n",
      "[4]\ttraining's auc: 0.785614\ttraining's binary_logloss: 0.0841296\tvalid_1's auc: 0.768015\tvalid_1's binary_logloss: 0.106362\n",
      "[5]\ttraining's auc: 0.79808\ttraining's binary_logloss: 0.0832829\tvalid_1's auc: 0.782823\tvalid_1's binary_logloss: 0.105157\n",
      "[6]\ttraining's auc: 0.798957\ttraining's binary_logloss: 0.0825228\tvalid_1's auc: 0.783147\tvalid_1's binary_logloss: 0.104134\n",
      "[7]\ttraining's auc: 0.799081\ttraining's binary_logloss: 0.0821122\tvalid_1's auc: 0.781683\tvalid_1's binary_logloss: 0.103707\n",
      "[8]\ttraining's auc: 0.799412\ttraining's binary_logloss: 0.0814982\tvalid_1's auc: 0.783838\tvalid_1's binary_logloss: 0.102936\n",
      "[9]\ttraining's auc: 0.801202\ttraining's binary_logloss: 0.0808916\tvalid_1's auc: 0.785921\tvalid_1's binary_logloss: 0.102128\n",
      "[10]\ttraining's auc: 0.801876\ttraining's binary_logloss: 0.0806186\tvalid_1's auc: 0.785232\tvalid_1's binary_logloss: 0.101833\n",
      "[11]\ttraining's auc: 0.802208\ttraining's binary_logloss: 0.0801273\tvalid_1's auc: 0.784914\tvalid_1's binary_logloss: 0.101233\n",
      "[12]\ttraining's auc: 0.802796\ttraining's binary_logloss: 0.0797167\tvalid_1's auc: 0.786252\tvalid_1's binary_logloss: 0.100718\n",
      "[13]\ttraining's auc: 0.802697\ttraining's binary_logloss: 0.0795035\tvalid_1's auc: 0.785844\tvalid_1's binary_logloss: 0.100485\n",
      "[14]\ttraining's auc: 0.80318\ttraining's binary_logloss: 0.0791192\tvalid_1's auc: 0.786648\tvalid_1's binary_logloss: 0.100034\n",
      "[15]\ttraining's auc: 0.803128\ttraining's binary_logloss: 0.0787713\tvalid_1's auc: 0.787153\tvalid_1's binary_logloss: 0.0996265\n",
      "[16]\ttraining's auc: 0.803674\ttraining's binary_logloss: 0.0784644\tvalid_1's auc: 0.787695\tvalid_1's binary_logloss: 0.09926\n",
      "[17]\ttraining's auc: 0.804562\ttraining's binary_logloss: 0.0782762\tvalid_1's auc: 0.787497\tvalid_1's binary_logloss: 0.0990753\n",
      "[18]\ttraining's auc: 0.804588\ttraining's binary_logloss: 0.0780198\tvalid_1's auc: 0.787855\tvalid_1's binary_logloss: 0.0987797\n",
      "[19]\ttraining's auc: 0.804856\ttraining's binary_logloss: 0.0777733\tvalid_1's auc: 0.788215\tvalid_1's binary_logloss: 0.0984624\n",
      "[20]\ttraining's auc: 0.805389\ttraining's binary_logloss: 0.0776052\tvalid_1's auc: 0.788883\tvalid_1's binary_logloss: 0.0982687\n",
      "[21]\ttraining's auc: 0.80535\ttraining's binary_logloss: 0.0774064\tvalid_1's auc: 0.789094\tvalid_1's binary_logloss: 0.0980445\n",
      "[22]\ttraining's auc: 0.805832\ttraining's binary_logloss: 0.0772279\tvalid_1's auc: 0.789989\tvalid_1's binary_logloss: 0.0978326\n",
      "[23]\ttraining's auc: 0.805626\ttraining's binary_logloss: 0.0770947\tvalid_1's auc: 0.789626\tvalid_1's binary_logloss: 0.0977211\n",
      "[24]\ttraining's auc: 0.805821\ttraining's binary_logloss: 0.0769216\tvalid_1's auc: 0.789687\tvalid_1's binary_logloss: 0.0975427\n",
      "[25]\ttraining's auc: 0.806713\ttraining's binary_logloss: 0.0767715\tvalid_1's auc: 0.790581\tvalid_1's binary_logloss: 0.0973363\n",
      "[26]\ttraining's auc: 0.806634\ttraining's binary_logloss: 0.0766375\tvalid_1's auc: 0.790566\tvalid_1's binary_logloss: 0.0972061\n",
      "[27]\ttraining's auc: 0.806535\ttraining's binary_logloss: 0.0765064\tvalid_1's auc: 0.79047\tvalid_1's binary_logloss: 0.0970804\n",
      "[28]\ttraining's auc: 0.807531\ttraining's binary_logloss: 0.0764124\tvalid_1's auc: 0.791324\tvalid_1's binary_logloss: 0.0969867\n",
      "[29]\ttraining's auc: 0.80751\ttraining's binary_logloss: 0.0763011\tvalid_1's auc: 0.79131\tvalid_1's binary_logloss: 0.0968865\n",
      "[30]\ttraining's auc: 0.807677\ttraining's binary_logloss: 0.0761941\tvalid_1's auc: 0.791657\tvalid_1's binary_logloss: 0.0967636\n",
      "[31]\ttraining's auc: 0.808178\ttraining's binary_logloss: 0.0760931\tvalid_1's auc: 0.792211\tvalid_1's binary_logloss: 0.0966492\n",
      "[32]\ttraining's auc: 0.808237\ttraining's binary_logloss: 0.0760263\tvalid_1's auc: 0.791882\tvalid_1's binary_logloss: 0.0966079\n",
      "[33]\ttraining's auc: 0.808377\ttraining's binary_logloss: 0.0759377\tvalid_1's auc: 0.792189\tvalid_1's binary_logloss: 0.0965059\n",
      "[34]\ttraining's auc: 0.808753\ttraining's binary_logloss: 0.0758853\tvalid_1's auc: 0.792333\tvalid_1's binary_logloss: 0.096474\n",
      "[35]\ttraining's auc: 0.808806\ttraining's binary_logloss: 0.0758101\tvalid_1's auc: 0.79303\tvalid_1's binary_logloss: 0.096386\n",
      "[36]\ttraining's auc: 0.808827\ttraining's binary_logloss: 0.0757494\tvalid_1's auc: 0.79308\tvalid_1's binary_logloss: 0.096316\n",
      "[37]\ttraining's auc: 0.809183\ttraining's binary_logloss: 0.0756719\tvalid_1's auc: 0.793709\tvalid_1's binary_logloss: 0.0962386\n",
      "[38]\ttraining's auc: 0.809257\ttraining's binary_logloss: 0.0756061\tvalid_1's auc: 0.794152\tvalid_1's binary_logloss: 0.0961597\n",
      "[39]\ttraining's auc: 0.809687\ttraining's binary_logloss: 0.0755395\tvalid_1's auc: 0.795144\tvalid_1's binary_logloss: 0.0960838\n",
      "[40]\ttraining's auc: 0.810185\ttraining's binary_logloss: 0.0754849\tvalid_1's auc: 0.795615\tvalid_1's binary_logloss: 0.0960232\n",
      "[41]\ttraining's auc: 0.810688\ttraining's binary_logloss: 0.0754276\tvalid_1's auc: 0.795945\tvalid_1's binary_logloss: 0.0959741\n",
      "[42]\ttraining's auc: 0.810748\ttraining's binary_logloss: 0.0753825\tvalid_1's auc: 0.795922\tvalid_1's binary_logloss: 0.0959403\n",
      "[43]\ttraining's auc: 0.811063\ttraining's binary_logloss: 0.0753409\tvalid_1's auc: 0.796153\tvalid_1's binary_logloss: 0.0959146\n",
      "[44]\ttraining's auc: 0.811224\ttraining's binary_logloss: 0.0752957\tvalid_1's auc: 0.796235\tvalid_1's binary_logloss: 0.0958662\n",
      "[45]\ttraining's auc: 0.811098\ttraining's binary_logloss: 0.0752433\tvalid_1's auc: 0.79586\tvalid_1's binary_logloss: 0.0958438\n",
      "[46]\ttraining's auc: 0.811677\ttraining's binary_logloss: 0.0751984\tvalid_1's auc: 0.796908\tvalid_1's binary_logloss: 0.095804\n",
      "[47]\ttraining's auc: 0.812068\ttraining's binary_logloss: 0.0751517\tvalid_1's auc: 0.797222\tvalid_1's binary_logloss: 0.0957643\n",
      "[48]\ttraining's auc: 0.812068\ttraining's binary_logloss: 0.0751066\tvalid_1's auc: 0.797407\tvalid_1's binary_logloss: 0.0957303\n",
      "[49]\ttraining's auc: 0.812315\ttraining's binary_logloss: 0.0750742\tvalid_1's auc: 0.797742\tvalid_1's binary_logloss: 0.0957043\n",
      "[50]\ttraining's auc: 0.812193\ttraining's binary_logloss: 0.075035\tvalid_1's auc: 0.797805\tvalid_1's binary_logloss: 0.0956603\n",
      "[51]\ttraining's auc: 0.812398\ttraining's binary_logloss: 0.0750107\tvalid_1's auc: 0.79826\tvalid_1's binary_logloss: 0.0956265\n",
      "[52]\ttraining's auc: 0.812448\ttraining's binary_logloss: 0.0749867\tvalid_1's auc: 0.7984\tvalid_1's binary_logloss: 0.0956\n",
      "[53]\ttraining's auc: 0.812505\ttraining's binary_logloss: 0.0749668\tvalid_1's auc: 0.798497\tvalid_1's binary_logloss: 0.0955708\n",
      "[54]\ttraining's auc: 0.812613\ttraining's binary_logloss: 0.0749391\tvalid_1's auc: 0.798727\tvalid_1's binary_logloss: 0.0955301\n",
      "[55]\ttraining's auc: 0.812745\ttraining's binary_logloss: 0.0749106\tvalid_1's auc: 0.798982\tvalid_1's binary_logloss: 0.0954986\n",
      "[56]\ttraining's auc: 0.813099\ttraining's binary_logloss: 0.0748768\tvalid_1's auc: 0.799148\tvalid_1's binary_logloss: 0.0954647\n",
      "[57]\ttraining's auc: 0.81328\ttraining's binary_logloss: 0.0748458\tvalid_1's auc: 0.799214\tvalid_1's binary_logloss: 0.0954446\n",
      "[58]\ttraining's auc: 0.813451\ttraining's binary_logloss: 0.074818\tvalid_1's auc: 0.799341\tvalid_1's binary_logloss: 0.0954327\n",
      "[59]\ttraining's auc: 0.813605\ttraining's binary_logloss: 0.0747929\tvalid_1's auc: 0.799612\tvalid_1's binary_logloss: 0.0954051\n",
      "[60]\ttraining's auc: 0.813714\ttraining's binary_logloss: 0.0747701\tvalid_1's auc: 0.799803\tvalid_1's binary_logloss: 0.0953861\n",
      "[61]\ttraining's auc: 0.813634\ttraining's binary_logloss: 0.0747407\tvalid_1's auc: 0.799942\tvalid_1's binary_logloss: 0.095374\n",
      "[62]\ttraining's auc: 0.813535\ttraining's binary_logloss: 0.074717\tvalid_1's auc: 0.800097\tvalid_1's binary_logloss: 0.0953561\n",
      "[63]\ttraining's auc: 0.813521\ttraining's binary_logloss: 0.0746957\tvalid_1's auc: 0.800189\tvalid_1's binary_logloss: 0.0953438\n",
      "[64]\ttraining's auc: 0.813528\ttraining's binary_logloss: 0.0746753\tvalid_1's auc: 0.800102\tvalid_1's binary_logloss: 0.0953255\n",
      "[65]\ttraining's auc: 0.81357\ttraining's binary_logloss: 0.0746536\tvalid_1's auc: 0.800311\tvalid_1's binary_logloss: 0.0953072\n",
      "[66]\ttraining's auc: 0.81374\ttraining's binary_logloss: 0.0746377\tvalid_1's auc: 0.800546\tvalid_1's binary_logloss: 0.0952973\n",
      "[67]\ttraining's auc: 0.813874\ttraining's binary_logloss: 0.0746233\tvalid_1's auc: 0.800887\tvalid_1's binary_logloss: 0.095278\n",
      "[68]\ttraining's auc: 0.814143\ttraining's binary_logloss: 0.0746075\tvalid_1's auc: 0.801114\tvalid_1's binary_logloss: 0.0952652\n",
      "[69]\ttraining's auc: 0.814221\ttraining's binary_logloss: 0.0745928\tvalid_1's auc: 0.801133\tvalid_1's binary_logloss: 0.0952573\n",
      "[70]\ttraining's auc: 0.814284\ttraining's binary_logloss: 0.0745781\tvalid_1's auc: 0.801393\tvalid_1's binary_logloss: 0.095239\n",
      "[71]\ttraining's auc: 0.814368\ttraining's binary_logloss: 0.0745616\tvalid_1's auc: 0.801597\tvalid_1's binary_logloss: 0.0952229\n",
      "[72]\ttraining's auc: 0.814504\ttraining's binary_logloss: 0.0745431\tvalid_1's auc: 0.802012\tvalid_1's binary_logloss: 0.0952005\n",
      "[73]\ttraining's auc: 0.814563\ttraining's binary_logloss: 0.0745305\tvalid_1's auc: 0.801893\tvalid_1's binary_logloss: 0.0952057\n",
      "[74]\ttraining's auc: 0.814562\ttraining's binary_logloss: 0.074523\tvalid_1's auc: 0.802004\tvalid_1's binary_logloss: 0.0952063\n",
      "[75]\ttraining's auc: 0.814597\ttraining's binary_logloss: 0.074509\tvalid_1's auc: 0.80196\tvalid_1's binary_logloss: 0.0951936\n",
      "[76]\ttraining's auc: 0.814794\ttraining's binary_logloss: 0.0744949\tvalid_1's auc: 0.802097\tvalid_1's binary_logloss: 0.0951746\n",
      "[77]\ttraining's auc: 0.814982\ttraining's binary_logloss: 0.0744796\tvalid_1's auc: 0.802227\tvalid_1's binary_logloss: 0.0951714\n",
      "[78]\ttraining's auc: 0.815019\ttraining's binary_logloss: 0.0744618\tvalid_1's auc: 0.802245\tvalid_1's binary_logloss: 0.0951604\n",
      "[79]\ttraining's auc: 0.815101\ttraining's binary_logloss: 0.0744485\tvalid_1's auc: 0.802421\tvalid_1's binary_logloss: 0.0951487\n",
      "[80]\ttraining's auc: 0.815151\ttraining's binary_logloss: 0.0744375\tvalid_1's auc: 0.802459\tvalid_1's binary_logloss: 0.0951442\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[80]\ttraining's auc: 0.815151\ttraining's binary_logloss: 0.0744375\tvalid_1's auc: 0.802459\tvalid_1's binary_logloss: 0.0951442\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.730347\ttraining's binary_logloss: 0.0973531\tvalid_1's auc: 0.746153\tvalid_1's binary_logloss: 0.0662543\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.784643\ttraining's binary_logloss: 0.0959369\tvalid_1's auc: 0.790691\tvalid_1's binary_logloss: 0.0654012\n",
      "[3]\ttraining's auc: 0.789082\ttraining's binary_logloss: 0.0953758\tvalid_1's auc: 0.802344\tvalid_1's binary_logloss: 0.0649805\n",
      "[4]\ttraining's auc: 0.786326\ttraining's binary_logloss: 0.0948066\tvalid_1's auc: 0.799455\tvalid_1's binary_logloss: 0.0645839\n",
      "[5]\ttraining's auc: 0.791919\ttraining's binary_logloss: 0.0938076\tvalid_1's auc: 0.805947\tvalid_1's binary_logloss: 0.0638862\n",
      "[6]\ttraining's auc: 0.791494\ttraining's binary_logloss: 0.0930058\tvalid_1's auc: 0.804091\tvalid_1's binary_logloss: 0.0633804\n",
      "[7]\ttraining's auc: 0.792345\ttraining's binary_logloss: 0.0926092\tvalid_1's auc: 0.804251\tvalid_1's binary_logloss: 0.0630972\n",
      "[8]\ttraining's auc: 0.793064\ttraining's binary_logloss: 0.0919349\tvalid_1's auc: 0.80601\tvalid_1's binary_logloss: 0.0625998\n",
      "[9]\ttraining's auc: 0.794182\ttraining's binary_logloss: 0.0913051\tvalid_1's auc: 0.808126\tvalid_1's binary_logloss: 0.0621007\n",
      "[10]\ttraining's auc: 0.794928\ttraining's binary_logloss: 0.0910205\tvalid_1's auc: 0.80572\tvalid_1's binary_logloss: 0.0618922\n",
      "[11]\ttraining's auc: 0.79524\ttraining's binary_logloss: 0.090501\tvalid_1's auc: 0.80703\tvalid_1's binary_logloss: 0.0614723\n",
      "[12]\ttraining's auc: 0.79574\ttraining's binary_logloss: 0.0900586\tvalid_1's auc: 0.808318\tvalid_1's binary_logloss: 0.0611114\n",
      "[13]\ttraining's auc: 0.79546\ttraining's binary_logloss: 0.0898371\tvalid_1's auc: 0.806084\tvalid_1's binary_logloss: 0.0609427\n",
      "[14]\ttraining's auc: 0.795859\ttraining's binary_logloss: 0.0894495\tvalid_1's auc: 0.807249\tvalid_1's binary_logloss: 0.060596\n",
      "[15]\ttraining's auc: 0.796052\ttraining's binary_logloss: 0.0890783\tvalid_1's auc: 0.808929\tvalid_1's binary_logloss: 0.0602894\n",
      "[16]\ttraining's auc: 0.796931\ttraining's binary_logloss: 0.0887567\tvalid_1's auc: 0.809481\tvalid_1's binary_logloss: 0.0600169\n",
      "[17]\ttraining's auc: 0.797487\ttraining's binary_logloss: 0.0885409\tvalid_1's auc: 0.810306\tvalid_1's binary_logloss: 0.0598276\n",
      "[18]\ttraining's auc: 0.797386\ttraining's binary_logloss: 0.088272\tvalid_1's auc: 0.810957\tvalid_1's binary_logloss: 0.0595831\n",
      "[19]\ttraining's auc: 0.797783\ttraining's binary_logloss: 0.0880119\tvalid_1's auc: 0.811418\tvalid_1's binary_logloss: 0.0593429\n",
      "[20]\ttraining's auc: 0.799486\ttraining's binary_logloss: 0.0878218\tvalid_1's auc: 0.810457\tvalid_1's binary_logloss: 0.0591831\n",
      "[21]\ttraining's auc: 0.799557\ttraining's binary_logloss: 0.0876093\tvalid_1's auc: 0.810367\tvalid_1's binary_logloss: 0.0589851\n",
      "[22]\ttraining's auc: 0.800037\ttraining's binary_logloss: 0.0874158\tvalid_1's auc: 0.811402\tvalid_1's binary_logloss: 0.0587923\n",
      "[23]\ttraining's auc: 0.800854\ttraining's binary_logloss: 0.087263\tvalid_1's auc: 0.811054\tvalid_1's binary_logloss: 0.0586657\n",
      "[24]\ttraining's auc: 0.800888\ttraining's binary_logloss: 0.0870833\tvalid_1's auc: 0.811045\tvalid_1's binary_logloss: 0.0584966\n",
      "[25]\ttraining's auc: 0.801352\ttraining's binary_logloss: 0.0868993\tvalid_1's auc: 0.811509\tvalid_1's binary_logloss: 0.0583259\n",
      "[26]\ttraining's auc: 0.801304\ttraining's binary_logloss: 0.0867486\tvalid_1's auc: 0.811852\tvalid_1's binary_logloss: 0.0581731\n",
      "[27]\ttraining's auc: 0.801356\ttraining's binary_logloss: 0.0866195\tvalid_1's auc: 0.811964\tvalid_1's binary_logloss: 0.058046\n",
      "[28]\ttraining's auc: 0.802675\ttraining's binary_logloss: 0.0865259\tvalid_1's auc: 0.812162\tvalid_1's binary_logloss: 0.0579675\n",
      "[29]\ttraining's auc: 0.802572\ttraining's binary_logloss: 0.0864057\tvalid_1's auc: 0.812596\tvalid_1's binary_logloss: 0.0578267\n",
      "[30]\ttraining's auc: 0.802746\ttraining's binary_logloss: 0.0862843\tvalid_1's auc: 0.813263\tvalid_1's binary_logloss: 0.0576991\n",
      "[31]\ttraining's auc: 0.803172\ttraining's binary_logloss: 0.0861779\tvalid_1's auc: 0.813785\tvalid_1's binary_logloss: 0.0575856\n",
      "[32]\ttraining's auc: 0.80326\ttraining's binary_logloss: 0.0861033\tvalid_1's auc: 0.813827\tvalid_1's binary_logloss: 0.057515\n",
      "[33]\ttraining's auc: 0.803658\ttraining's binary_logloss: 0.0860037\tvalid_1's auc: 0.813718\tvalid_1's binary_logloss: 0.0574186\n",
      "[34]\ttraining's auc: 0.804209\ttraining's binary_logloss: 0.0859439\tvalid_1's auc: 0.813551\tvalid_1's binary_logloss: 0.0573574\n",
      "[35]\ttraining's auc: 0.804444\ttraining's binary_logloss: 0.0858615\tvalid_1's auc: 0.813784\tvalid_1's binary_logloss: 0.0572712\n",
      "[36]\ttraining's auc: 0.804486\ttraining's binary_logloss: 0.0857884\tvalid_1's auc: 0.813859\tvalid_1's binary_logloss: 0.0572145\n",
      "[37]\ttraining's auc: 0.804945\ttraining's binary_logloss: 0.0857096\tvalid_1's auc: 0.81533\tvalid_1's binary_logloss: 0.0571436\n",
      "[38]\ttraining's auc: 0.80507\ttraining's binary_logloss: 0.0856327\tvalid_1's auc: 0.814838\tvalid_1's binary_logloss: 0.0570514\n",
      "[39]\ttraining's auc: 0.805467\ttraining's binary_logloss: 0.0855602\tvalid_1's auc: 0.815411\tvalid_1's binary_logloss: 0.0569847\n",
      "[40]\ttraining's auc: 0.805484\ttraining's binary_logloss: 0.0855052\tvalid_1's auc: 0.814968\tvalid_1's binary_logloss: 0.0569331\n",
      "[41]\ttraining's auc: 0.805575\ttraining's binary_logloss: 0.085437\tvalid_1's auc: 0.814742\tvalid_1's binary_logloss: 0.0568484\n",
      "[42]\ttraining's auc: 0.805705\ttraining's binary_logloss: 0.0853839\tvalid_1's auc: 0.814734\tvalid_1's binary_logloss: 0.0567924\n",
      "[43]\ttraining's auc: 0.805655\ttraining's binary_logloss: 0.0853263\tvalid_1's auc: 0.814792\tvalid_1's binary_logloss: 0.0567316\n",
      "[44]\ttraining's auc: 0.805827\ttraining's binary_logloss: 0.0852791\tvalid_1's auc: 0.814882\tvalid_1's binary_logloss: 0.0566794\n",
      "[45]\ttraining's auc: 0.806062\ttraining's binary_logloss: 0.0852219\tvalid_1's auc: 0.815107\tvalid_1's binary_logloss: 0.0566252\n",
      "[46]\ttraining's auc: 0.805973\ttraining's binary_logloss: 0.0851788\tvalid_1's auc: 0.814832\tvalid_1's binary_logloss: 0.05658\n",
      "[47]\ttraining's auc: 0.8062\ttraining's binary_logloss: 0.0851374\tvalid_1's auc: 0.814829\tvalid_1's binary_logloss: 0.0565284\n",
      "[48]\ttraining's auc: 0.806433\ttraining's binary_logloss: 0.0850893\tvalid_1's auc: 0.81472\tvalid_1's binary_logloss: 0.0564771\n",
      "[49]\ttraining's auc: 0.806647\ttraining's binary_logloss: 0.0850431\tvalid_1's auc: 0.81491\tvalid_1's binary_logloss: 0.0564311\n",
      "[50]\ttraining's auc: 0.806568\ttraining's binary_logloss: 0.0850022\tvalid_1's auc: 0.814637\tvalid_1's binary_logloss: 0.0563811\n",
      "[51]\ttraining's auc: 0.806722\ttraining's binary_logloss: 0.084969\tvalid_1's auc: 0.814831\tvalid_1's binary_logloss: 0.0563503\n",
      "[52]\ttraining's auc: 0.806686\ttraining's binary_logloss: 0.0849264\tvalid_1's auc: 0.815347\tvalid_1's binary_logloss: 0.0563003\n",
      "[53]\ttraining's auc: 0.806864\ttraining's binary_logloss: 0.0849003\tvalid_1's auc: 0.815294\tvalid_1's binary_logloss: 0.0562744\n",
      "[54]\ttraining's auc: 0.807012\ttraining's binary_logloss: 0.0848644\tvalid_1's auc: 0.815161\tvalid_1's binary_logloss: 0.0562394\n",
      "[55]\ttraining's auc: 0.807071\ttraining's binary_logloss: 0.0848348\tvalid_1's auc: 0.815044\tvalid_1's binary_logloss: 0.0562107\n",
      "[56]\ttraining's auc: 0.807192\ttraining's binary_logloss: 0.0848079\tvalid_1's auc: 0.815161\tvalid_1's binary_logloss: 0.0561835\n",
      "[57]\ttraining's auc: 0.807266\ttraining's binary_logloss: 0.0847812\tvalid_1's auc: 0.815412\tvalid_1's binary_logloss: 0.0561607\n",
      "[58]\ttraining's auc: 0.807522\ttraining's binary_logloss: 0.0847539\tvalid_1's auc: 0.815017\tvalid_1's binary_logloss: 0.0561352\n",
      "[59]\ttraining's auc: 0.807756\ttraining's binary_logloss: 0.0847271\tvalid_1's auc: 0.815526\tvalid_1's binary_logloss: 0.0561127\n",
      "[60]\ttraining's auc: 0.807906\ttraining's binary_logloss: 0.0847052\tvalid_1's auc: 0.815651\tvalid_1's binary_logloss: 0.0560871\n",
      "[61]\ttraining's auc: 0.807908\ttraining's binary_logloss: 0.0846771\tvalid_1's auc: 0.81586\tvalid_1's binary_logloss: 0.0560598\n",
      "[62]\ttraining's auc: 0.807825\ttraining's binary_logloss: 0.0846535\tvalid_1's auc: 0.815716\tvalid_1's binary_logloss: 0.0560395\n",
      "[63]\ttraining's auc: 0.807979\ttraining's binary_logloss: 0.0846277\tvalid_1's auc: 0.815459\tvalid_1's binary_logloss: 0.0560157\n",
      "[64]\ttraining's auc: 0.808122\ttraining's binary_logloss: 0.084603\tvalid_1's auc: 0.815693\tvalid_1's binary_logloss: 0.0559968\n",
      "[65]\ttraining's auc: 0.808225\ttraining's binary_logloss: 0.084582\tvalid_1's auc: 0.815806\tvalid_1's binary_logloss: 0.0559781\n",
      "[66]\ttraining's auc: 0.80833\ttraining's binary_logloss: 0.0845667\tvalid_1's auc: 0.815883\tvalid_1's binary_logloss: 0.0559607\n",
      "[67]\ttraining's auc: 0.808585\ttraining's binary_logloss: 0.0845463\tvalid_1's auc: 0.815894\tvalid_1's binary_logloss: 0.0559384\n",
      "[68]\ttraining's auc: 0.808854\ttraining's binary_logloss: 0.0845274\tvalid_1's auc: 0.815614\tvalid_1's binary_logloss: 0.0559353\n",
      "[69]\ttraining's auc: 0.808877\ttraining's binary_logloss: 0.0845188\tvalid_1's auc: 0.815212\tvalid_1's binary_logloss: 0.0559384\n",
      "[70]\ttraining's auc: 0.808971\ttraining's binary_logloss: 0.0845027\tvalid_1's auc: 0.815137\tvalid_1's binary_logloss: 0.0559341\n",
      "[71]\ttraining's auc: 0.809045\ttraining's binary_logloss: 0.0844853\tvalid_1's auc: 0.815219\tvalid_1's binary_logloss: 0.055911\n",
      "[72]\ttraining's auc: 0.809042\ttraining's binary_logloss: 0.0844673\tvalid_1's auc: 0.815066\tvalid_1's binary_logloss: 0.0558948\n",
      "[73]\ttraining's auc: 0.809116\ttraining's binary_logloss: 0.0844553\tvalid_1's auc: 0.815337\tvalid_1's binary_logloss: 0.0558831\n",
      "[74]\ttraining's auc: 0.809289\ttraining's binary_logloss: 0.0844443\tvalid_1's auc: 0.815503\tvalid_1's binary_logloss: 0.0558681\n",
      "[75]\ttraining's auc: 0.809309\ttraining's binary_logloss: 0.0844295\tvalid_1's auc: 0.81553\tvalid_1's binary_logloss: 0.0558534\n",
      "[76]\ttraining's auc: 0.809421\ttraining's binary_logloss: 0.0844129\tvalid_1's auc: 0.815692\tvalid_1's binary_logloss: 0.0558498\n",
      "[77]\ttraining's auc: 0.809427\ttraining's binary_logloss: 0.0843957\tvalid_1's auc: 0.81563\tvalid_1's binary_logloss: 0.0558328\n",
      "[78]\ttraining's auc: 0.809453\ttraining's binary_logloss: 0.0843765\tvalid_1's auc: 0.815666\tvalid_1's binary_logloss: 0.0558153\n",
      "[79]\ttraining's auc: 0.809528\ttraining's binary_logloss: 0.0843643\tvalid_1's auc: 0.815543\tvalid_1's binary_logloss: 0.0558216\n",
      "[80]\ttraining's auc: 0.809577\ttraining's binary_logloss: 0.0843499\tvalid_1's auc: 0.81583\tvalid_1's binary_logloss: 0.0557993\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[80]\ttraining's auc: 0.809577\ttraining's binary_logloss: 0.0843499\tvalid_1's auc: 0.81583\tvalid_1's binary_logloss: 0.0557993\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.730749\ttraining's binary_logloss: 0.0961633\tvalid_1's auc: 0.742913\tvalid_1's binary_logloss: 0.0709548\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.784028\ttraining's binary_logloss: 0.0947491\tvalid_1's auc: 0.797433\tvalid_1's binary_logloss: 0.0699955\n",
      "[3]\ttraining's auc: 0.788859\ttraining's binary_logloss: 0.0942243\tvalid_1's auc: 0.804463\tvalid_1's binary_logloss: 0.0695991\n",
      "[4]\ttraining's auc: 0.788094\ttraining's binary_logloss: 0.0936544\tvalid_1's auc: 0.800355\tvalid_1's binary_logloss: 0.069149\n",
      "[5]\ttraining's auc: 0.793122\ttraining's binary_logloss: 0.0926345\tvalid_1's auc: 0.803236\tvalid_1's binary_logloss: 0.068461\n",
      "[6]\ttraining's auc: 0.794215\ttraining's binary_logloss: 0.0917177\tvalid_1's auc: 0.80357\tvalid_1's binary_logloss: 0.0678381\n",
      "[7]\ttraining's auc: 0.794273\ttraining's binary_logloss: 0.0913001\tvalid_1's auc: 0.802532\tvalid_1's binary_logloss: 0.0674945\n",
      "[8]\ttraining's auc: 0.794774\ttraining's binary_logloss: 0.0906156\tvalid_1's auc: 0.802836\tvalid_1's binary_logloss: 0.0670167\n",
      "[9]\ttraining's auc: 0.795662\ttraining's binary_logloss: 0.0899819\tvalid_1's auc: 0.803685\tvalid_1's binary_logloss: 0.0665586\n",
      "[10]\ttraining's auc: 0.796146\ttraining's binary_logloss: 0.0897168\tvalid_1's auc: 0.805366\tvalid_1's binary_logloss: 0.0663114\n",
      "[11]\ttraining's auc: 0.796625\ttraining's binary_logloss: 0.0892145\tvalid_1's auc: 0.807456\tvalid_1's binary_logloss: 0.0659167\n",
      "[12]\ttraining's auc: 0.79694\ttraining's binary_logloss: 0.0887677\tvalid_1's auc: 0.809563\tvalid_1's binary_logloss: 0.0655383\n",
      "[13]\ttraining's auc: 0.796783\ttraining's binary_logloss: 0.0885507\tvalid_1's auc: 0.809199\tvalid_1's binary_logloss: 0.0653411\n",
      "[14]\ttraining's auc: 0.796407\ttraining's binary_logloss: 0.0881473\tvalid_1's auc: 0.808661\tvalid_1's binary_logloss: 0.0650116\n",
      "[15]\ttraining's auc: 0.797193\ttraining's binary_logloss: 0.0877834\tvalid_1's auc: 0.80988\tvalid_1's binary_logloss: 0.0647292\n",
      "[16]\ttraining's auc: 0.79679\ttraining's binary_logloss: 0.0874629\tvalid_1's auc: 0.809688\tvalid_1's binary_logloss: 0.0644529\n",
      "[17]\ttraining's auc: 0.798097\ttraining's binary_logloss: 0.0872538\tvalid_1's auc: 0.810618\tvalid_1's binary_logloss: 0.0642563\n",
      "[18]\ttraining's auc: 0.798006\ttraining's binary_logloss: 0.0869944\tvalid_1's auc: 0.810322\tvalid_1's binary_logloss: 0.0640333\n",
      "[19]\ttraining's auc: 0.799009\ttraining's binary_logloss: 0.0867339\tvalid_1's auc: 0.812054\tvalid_1's binary_logloss: 0.0637932\n",
      "[20]\ttraining's auc: 0.799827\ttraining's binary_logloss: 0.0865587\tvalid_1's auc: 0.813022\tvalid_1's binary_logloss: 0.063626\n",
      "[21]\ttraining's auc: 0.799805\ttraining's binary_logloss: 0.086356\tvalid_1's auc: 0.813127\tvalid_1's binary_logloss: 0.0634464\n",
      "[22]\ttraining's auc: 0.800228\ttraining's binary_logloss: 0.0861655\tvalid_1's auc: 0.813698\tvalid_1's binary_logloss: 0.0632564\n",
      "[23]\ttraining's auc: 0.800426\ttraining's binary_logloss: 0.0860253\tvalid_1's auc: 0.81439\tvalid_1's binary_logloss: 0.0631232\n",
      "[24]\ttraining's auc: 0.800352\ttraining's binary_logloss: 0.0858502\tvalid_1's auc: 0.814154\tvalid_1's binary_logloss: 0.0629754\n",
      "[25]\ttraining's auc: 0.800805\ttraining's binary_logloss: 0.0856703\tvalid_1's auc: 0.81578\tvalid_1's binary_logloss: 0.0628145\n",
      "[26]\ttraining's auc: 0.800391\ttraining's binary_logloss: 0.0855272\tvalid_1's auc: 0.814905\tvalid_1's binary_logloss: 0.0626772\n",
      "[27]\ttraining's auc: 0.800352\ttraining's binary_logloss: 0.0854034\tvalid_1's auc: 0.814819\tvalid_1's binary_logloss: 0.0625652\n",
      "[28]\ttraining's auc: 0.801818\ttraining's binary_logloss: 0.0853141\tvalid_1's auc: 0.815369\tvalid_1's binary_logloss: 0.0624889\n",
      "[29]\ttraining's auc: 0.801923\ttraining's binary_logloss: 0.0851895\tvalid_1's auc: 0.816079\tvalid_1's binary_logloss: 0.0623599\n",
      "[30]\ttraining's auc: 0.802866\ttraining's binary_logloss: 0.0850684\tvalid_1's auc: 0.818307\tvalid_1's binary_logloss: 0.0622376\n",
      "[31]\ttraining's auc: 0.80303\ttraining's binary_logloss: 0.0849616\tvalid_1's auc: 0.817998\tvalid_1's binary_logloss: 0.0621342\n",
      "[32]\ttraining's auc: 0.8032\ttraining's binary_logloss: 0.0848904\tvalid_1's auc: 0.818715\tvalid_1's binary_logloss: 0.062045\n",
      "[33]\ttraining's auc: 0.803554\ttraining's binary_logloss: 0.084791\tvalid_1's auc: 0.818353\tvalid_1's binary_logloss: 0.0619613\n",
      "[34]\ttraining's auc: 0.803704\ttraining's binary_logloss: 0.0847369\tvalid_1's auc: 0.818047\tvalid_1's binary_logloss: 0.06189\n",
      "[35]\ttraining's auc: 0.804011\ttraining's binary_logloss: 0.0846602\tvalid_1's auc: 0.81893\tvalid_1's binary_logloss: 0.061801\n",
      "[36]\ttraining's auc: 0.80415\ttraining's binary_logloss: 0.084594\tvalid_1's auc: 0.819485\tvalid_1's binary_logloss: 0.0617198\n",
      "[37]\ttraining's auc: 0.804479\ttraining's binary_logloss: 0.0845205\tvalid_1's auc: 0.819578\tvalid_1's binary_logloss: 0.0616303\n",
      "[38]\ttraining's auc: 0.804591\ttraining's binary_logloss: 0.0844439\tvalid_1's auc: 0.819611\tvalid_1's binary_logloss: 0.061551\n",
      "[39]\ttraining's auc: 0.804917\ttraining's binary_logloss: 0.0843732\tvalid_1's auc: 0.81937\tvalid_1's binary_logloss: 0.0614767\n",
      "[40]\ttraining's auc: 0.805168\ttraining's binary_logloss: 0.084307\tvalid_1's auc: 0.81904\tvalid_1's binary_logloss: 0.0614045\n",
      "[41]\ttraining's auc: 0.805101\ttraining's binary_logloss: 0.0842394\tvalid_1's auc: 0.819597\tvalid_1's binary_logloss: 0.0613289\n",
      "[42]\ttraining's auc: 0.805366\ttraining's binary_logloss: 0.0841893\tvalid_1's auc: 0.819161\tvalid_1's binary_logloss: 0.0612731\n",
      "[43]\ttraining's auc: 0.805585\ttraining's binary_logloss: 0.0841439\tvalid_1's auc: 0.819247\tvalid_1's binary_logloss: 0.0612279\n",
      "[44]\ttraining's auc: 0.805655\ttraining's binary_logloss: 0.0841003\tvalid_1's auc: 0.81963\tvalid_1's binary_logloss: 0.0611558\n",
      "[45]\ttraining's auc: 0.805859\ttraining's binary_logloss: 0.0840439\tvalid_1's auc: 0.819395\tvalid_1's binary_logloss: 0.0611003\n",
      "[46]\ttraining's auc: 0.806262\ttraining's binary_logloss: 0.0839955\tvalid_1's auc: 0.820188\tvalid_1's binary_logloss: 0.0610605\n",
      "[47]\ttraining's auc: 0.806468\ttraining's binary_logloss: 0.0839516\tvalid_1's auc: 0.82017\tvalid_1's binary_logloss: 0.061004\n",
      "[48]\ttraining's auc: 0.8067\ttraining's binary_logloss: 0.0839061\tvalid_1's auc: 0.820392\tvalid_1's binary_logloss: 0.0609647\n",
      "[49]\ttraining's auc: 0.806929\ttraining's binary_logloss: 0.0838587\tvalid_1's auc: 0.820826\tvalid_1's binary_logloss: 0.0609038\n",
      "[50]\ttraining's auc: 0.807089\ttraining's binary_logloss: 0.0838216\tvalid_1's auc: 0.820821\tvalid_1's binary_logloss: 0.0608608\n",
      "[51]\ttraining's auc: 0.807181\ttraining's binary_logloss: 0.0837891\tvalid_1's auc: 0.821273\tvalid_1's binary_logloss: 0.0608166\n",
      "[52]\ttraining's auc: 0.807257\ttraining's binary_logloss: 0.0837462\tvalid_1's auc: 0.821287\tvalid_1's binary_logloss: 0.0607748\n",
      "[53]\ttraining's auc: 0.807363\ttraining's binary_logloss: 0.0837182\tvalid_1's auc: 0.821665\tvalid_1's binary_logloss: 0.0607496\n",
      "[54]\ttraining's auc: 0.80749\ttraining's binary_logloss: 0.0836762\tvalid_1's auc: 0.821429\tvalid_1's binary_logloss: 0.060718\n",
      "[55]\ttraining's auc: 0.807735\ttraining's binary_logloss: 0.0836466\tvalid_1's auc: 0.821384\tvalid_1's binary_logloss: 0.0606832\n",
      "[56]\ttraining's auc: 0.807724\ttraining's binary_logloss: 0.0836164\tvalid_1's auc: 0.820822\tvalid_1's binary_logloss: 0.0606668\n",
      "[57]\ttraining's auc: 0.807636\ttraining's binary_logloss: 0.0835872\tvalid_1's auc: 0.820919\tvalid_1's binary_logloss: 0.0606504\n",
      "[58]\ttraining's auc: 0.80759\ttraining's binary_logloss: 0.08356\tvalid_1's auc: 0.821101\tvalid_1's binary_logloss: 0.0606177\n",
      "[59]\ttraining's auc: 0.80776\ttraining's binary_logloss: 0.0835347\tvalid_1's auc: 0.821095\tvalid_1's binary_logloss: 0.0606016\n",
      "[60]\ttraining's auc: 0.807931\ttraining's binary_logloss: 0.0835121\tvalid_1's auc: 0.821164\tvalid_1's binary_logloss: 0.0605791\n",
      "[61]\ttraining's auc: 0.808173\ttraining's binary_logloss: 0.0834877\tvalid_1's auc: 0.821144\tvalid_1's binary_logloss: 0.0605648\n",
      "[62]\ttraining's auc: 0.808135\ttraining's binary_logloss: 0.0834663\tvalid_1's auc: 0.82103\tvalid_1's binary_logloss: 0.0605446\n",
      "[63]\ttraining's auc: 0.808258\ttraining's binary_logloss: 0.0834457\tvalid_1's auc: 0.820971\tvalid_1's binary_logloss: 0.0605161\n",
      "[64]\ttraining's auc: 0.808281\ttraining's binary_logloss: 0.0834215\tvalid_1's auc: 0.820993\tvalid_1's binary_logloss: 0.0604997\n",
      "[65]\ttraining's auc: 0.808472\ttraining's binary_logloss: 0.0833987\tvalid_1's auc: 0.821043\tvalid_1's binary_logloss: 0.0604765\n",
      "[66]\ttraining's auc: 0.808539\ttraining's binary_logloss: 0.0833827\tvalid_1's auc: 0.82095\tvalid_1's binary_logloss: 0.0604534\n",
      "[67]\ttraining's auc: 0.80868\ttraining's binary_logloss: 0.083365\tvalid_1's auc: 0.820823\tvalid_1's binary_logloss: 0.0604365\n",
      "[68]\ttraining's auc: 0.808902\ttraining's binary_logloss: 0.0833306\tvalid_1's auc: 0.821164\tvalid_1's binary_logloss: 0.0604114\n",
      "[69]\ttraining's auc: 0.808963\ttraining's binary_logloss: 0.0833054\tvalid_1's auc: 0.821152\tvalid_1's binary_logloss: 0.0603806\n",
      "[70]\ttraining's auc: 0.809065\ttraining's binary_logloss: 0.0832896\tvalid_1's auc: 0.820988\tvalid_1's binary_logloss: 0.0603731\n",
      "[71]\ttraining's auc: 0.809131\ttraining's binary_logloss: 0.0832733\tvalid_1's auc: 0.820796\tvalid_1's binary_logloss: 0.060353\n",
      "[72]\ttraining's auc: 0.809242\ttraining's binary_logloss: 0.0832494\tvalid_1's auc: 0.821042\tvalid_1's binary_logloss: 0.0603353\n",
      "[73]\ttraining's auc: 0.809251\ttraining's binary_logloss: 0.0832331\tvalid_1's auc: 0.820673\tvalid_1's binary_logloss: 0.0603286\n",
      "[74]\ttraining's auc: 0.809299\ttraining's binary_logloss: 0.083222\tvalid_1's auc: 0.820532\tvalid_1's binary_logloss: 0.0603274\n",
      "[75]\ttraining's auc: 0.809464\ttraining's binary_logloss: 0.0832105\tvalid_1's auc: 0.820394\tvalid_1's binary_logloss: 0.0603293\n",
      "[76]\ttraining's auc: 0.809585\ttraining's binary_logloss: 0.0831955\tvalid_1's auc: 0.820388\tvalid_1's binary_logloss: 0.0603156\n",
      "[77]\ttraining's auc: 0.809747\ttraining's binary_logloss: 0.0831809\tvalid_1's auc: 0.820271\tvalid_1's binary_logloss: 0.0603137\n",
      "[78]\ttraining's auc: 0.809796\ttraining's binary_logloss: 0.0831612\tvalid_1's auc: 0.820245\tvalid_1's binary_logloss: 0.0602973\n",
      "[79]\ttraining's auc: 0.809824\ttraining's binary_logloss: 0.0831457\tvalid_1's auc: 0.820242\tvalid_1's binary_logloss: 0.0602737\n",
      "[80]\ttraining's auc: 0.809846\ttraining's binary_logloss: 0.0831342\tvalid_1's auc: 0.820216\tvalid_1's binary_logloss: 0.0602666\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[80]\ttraining's auc: 0.809846\ttraining's binary_logloss: 0.0831342\tvalid_1's auc: 0.820216\tvalid_1's binary_logloss: 0.0602666\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.7369\ttraining's binary_logloss: 0.0916053\tvalid_1's auc: 0.7262\tvalid_1's binary_logloss: 0.088886\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.793624\ttraining's binary_logloss: 0.0901081\tvalid_1's auc: 0.767404\tvalid_1's binary_logloss: 0.0878256\n",
      "[3]\ttraining's auc: 0.798711\ttraining's binary_logloss: 0.0895489\tvalid_1's auc: 0.774005\tvalid_1's binary_logloss: 0.0873619\n",
      "[4]\ttraining's auc: 0.799412\ttraining's binary_logloss: 0.0890054\tvalid_1's auc: 0.77414\tvalid_1's binary_logloss: 0.0869067\n",
      "[5]\ttraining's auc: 0.803779\ttraining's binary_logloss: 0.0880829\tvalid_1's auc: 0.776585\tvalid_1's binary_logloss: 0.0862555\n",
      "[6]\ttraining's auc: 0.804211\ttraining's binary_logloss: 0.087227\tvalid_1's auc: 0.776126\tvalid_1's binary_logloss: 0.0856483\n",
      "[7]\ttraining's auc: 0.803314\ttraining's binary_logloss: 0.0868094\tvalid_1's auc: 0.775453\tvalid_1's binary_logloss: 0.0852977\n",
      "[8]\ttraining's auc: 0.804279\ttraining's binary_logloss: 0.0860924\tvalid_1's auc: 0.775941\tvalid_1's binary_logloss: 0.0847639\n",
      "[9]\ttraining's auc: 0.805975\ttraining's binary_logloss: 0.0854646\tvalid_1's auc: 0.777475\tvalid_1's binary_logloss: 0.0842941\n",
      "[10]\ttraining's auc: 0.805989\ttraining's binary_logloss: 0.0851829\tvalid_1's auc: 0.776597\tvalid_1's binary_logloss: 0.0840807\n",
      "[11]\ttraining's auc: 0.806146\ttraining's binary_logloss: 0.084626\tvalid_1's auc: 0.776615\tvalid_1's binary_logloss: 0.0836775\n",
      "[12]\ttraining's auc: 0.807735\ttraining's binary_logloss: 0.0841373\tvalid_1's auc: 0.777433\tvalid_1's binary_logloss: 0.0833524\n",
      "[13]\ttraining's auc: 0.80815\ttraining's binary_logloss: 0.083907\tvalid_1's auc: 0.778567\tvalid_1's binary_logloss: 0.0831794\n",
      "[14]\ttraining's auc: 0.8085\ttraining's binary_logloss: 0.0834762\tvalid_1's auc: 0.779139\tvalid_1's binary_logloss: 0.0828748\n",
      "[15]\ttraining's auc: 0.8088\ttraining's binary_logloss: 0.0831041\tvalid_1's auc: 0.779599\tvalid_1's binary_logloss: 0.0826197\n",
      "[16]\ttraining's auc: 0.808836\ttraining's binary_logloss: 0.0827816\tvalid_1's auc: 0.779159\tvalid_1's binary_logloss: 0.0824344\n",
      "[17]\ttraining's auc: 0.808764\ttraining's binary_logloss: 0.0825583\tvalid_1's auc: 0.779135\tvalid_1's binary_logloss: 0.0822425\n",
      "[18]\ttraining's auc: 0.809898\ttraining's binary_logloss: 0.0822904\tvalid_1's auc: 0.779895\tvalid_1's binary_logloss: 0.08208\n",
      "[19]\ttraining's auc: 0.810305\ttraining's binary_logloss: 0.0820217\tvalid_1's auc: 0.78017\tvalid_1's binary_logloss: 0.0818671\n",
      "[20]\ttraining's auc: 0.810257\ttraining's binary_logloss: 0.0818533\tvalid_1's auc: 0.78061\tvalid_1's binary_logloss: 0.081711\n",
      "[21]\ttraining's auc: 0.810229\ttraining's binary_logloss: 0.081637\tvalid_1's auc: 0.780498\tvalid_1's binary_logloss: 0.0815919\n",
      "[22]\ttraining's auc: 0.81049\ttraining's binary_logloss: 0.0814333\tvalid_1's auc: 0.780998\tvalid_1's binary_logloss: 0.0814317\n",
      "[23]\ttraining's auc: 0.810853\ttraining's binary_logloss: 0.0812843\tvalid_1's auc: 0.782034\tvalid_1's binary_logloss: 0.0812936\n",
      "[24]\ttraining's auc: 0.810865\ttraining's binary_logloss: 0.0811005\tvalid_1's auc: 0.781915\tvalid_1's binary_logloss: 0.0812019\n",
      "[25]\ttraining's auc: 0.811411\ttraining's binary_logloss: 0.0809179\tvalid_1's auc: 0.782555\tvalid_1's binary_logloss: 0.0810784\n",
      "[26]\ttraining's auc: 0.811831\ttraining's binary_logloss: 0.0807615\tvalid_1's auc: 0.782595\tvalid_1's binary_logloss: 0.0810016\n",
      "[27]\ttraining's auc: 0.812533\ttraining's binary_logloss: 0.0806293\tvalid_1's auc: 0.782433\tvalid_1's binary_logloss: 0.0809393\n",
      "[28]\ttraining's auc: 0.813004\ttraining's binary_logloss: 0.0805518\tvalid_1's auc: 0.782505\tvalid_1's binary_logloss: 0.0808556\n",
      "[29]\ttraining's auc: 0.813944\ttraining's binary_logloss: 0.0804244\tvalid_1's auc: 0.78287\tvalid_1's binary_logloss: 0.0807739\n",
      "[30]\ttraining's auc: 0.81393\ttraining's binary_logloss: 0.0803039\tvalid_1's auc: 0.782935\tvalid_1's binary_logloss: 0.080679\n",
      "[31]\ttraining's auc: 0.814248\ttraining's binary_logloss: 0.0801919\tvalid_1's auc: 0.78356\tvalid_1's binary_logloss: 0.0806119\n",
      "[32]\ttraining's auc: 0.814152\ttraining's binary_logloss: 0.0801182\tvalid_1's auc: 0.783896\tvalid_1's binary_logloss: 0.080538\n",
      "[33]\ttraining's auc: 0.814973\ttraining's binary_logloss: 0.0800265\tvalid_1's auc: 0.785014\tvalid_1's binary_logloss: 0.0804548\n",
      "[34]\ttraining's auc: 0.814946\ttraining's binary_logloss: 0.0799604\tvalid_1's auc: 0.784776\tvalid_1's binary_logloss: 0.0804281\n",
      "[35]\ttraining's auc: 0.815168\ttraining's binary_logloss: 0.07987\tvalid_1's auc: 0.784543\tvalid_1's binary_logloss: 0.0803984\n",
      "[36]\ttraining's auc: 0.815285\ttraining's binary_logloss: 0.0798056\tvalid_1's auc: 0.784537\tvalid_1's binary_logloss: 0.0803779\n",
      "[37]\ttraining's auc: 0.816009\ttraining's binary_logloss: 0.0797318\tvalid_1's auc: 0.785455\tvalid_1's binary_logloss: 0.0803199\n",
      "[38]\ttraining's auc: 0.816104\ttraining's binary_logloss: 0.0796535\tvalid_1's auc: 0.785651\tvalid_1's binary_logloss: 0.0802644\n",
      "[39]\ttraining's auc: 0.816478\ttraining's binary_logloss: 0.0795767\tvalid_1's auc: 0.786218\tvalid_1's binary_logloss: 0.0801931\n",
      "[40]\ttraining's auc: 0.816644\ttraining's binary_logloss: 0.0795068\tvalid_1's auc: 0.785947\tvalid_1's binary_logloss: 0.0801397\n",
      "[41]\ttraining's auc: 0.816972\ttraining's binary_logloss: 0.0794396\tvalid_1's auc: 0.786279\tvalid_1's binary_logloss: 0.0800832\n",
      "[42]\ttraining's auc: 0.817289\ttraining's binary_logloss: 0.079396\tvalid_1's auc: 0.786501\tvalid_1's binary_logloss: 0.0800641\n",
      "[43]\ttraining's auc: 0.817678\ttraining's binary_logloss: 0.0793413\tvalid_1's auc: 0.786424\tvalid_1's binary_logloss: 0.0799994\n",
      "[44]\ttraining's auc: 0.817764\ttraining's binary_logloss: 0.0793085\tvalid_1's auc: 0.786383\tvalid_1's binary_logloss: 0.0799888\n",
      "[45]\ttraining's auc: 0.818065\ttraining's binary_logloss: 0.0792525\tvalid_1's auc: 0.786374\tvalid_1's binary_logloss: 0.0799347\n",
      "[46]\ttraining's auc: 0.818213\ttraining's binary_logloss: 0.0792125\tvalid_1's auc: 0.786818\tvalid_1's binary_logloss: 0.0798919\n",
      "[47]\ttraining's auc: 0.818225\ttraining's binary_logloss: 0.0791659\tvalid_1's auc: 0.786802\tvalid_1's binary_logloss: 0.0798885\n",
      "[48]\ttraining's auc: 0.818294\ttraining's binary_logloss: 0.0791129\tvalid_1's auc: 0.786973\tvalid_1's binary_logloss: 0.0798449\n",
      "[49]\ttraining's auc: 0.818384\ttraining's binary_logloss: 0.0790677\tvalid_1's auc: 0.787172\tvalid_1's binary_logloss: 0.0797988\n",
      "[50]\ttraining's auc: 0.81875\ttraining's binary_logloss: 0.0790338\tvalid_1's auc: 0.787674\tvalid_1's binary_logloss: 0.0797501\n",
      "[51]\ttraining's auc: 0.819018\ttraining's binary_logloss: 0.0790031\tvalid_1's auc: 0.787511\tvalid_1's binary_logloss: 0.0797522\n",
      "[52]\ttraining's auc: 0.819135\ttraining's binary_logloss: 0.0789693\tvalid_1's auc: 0.78737\tvalid_1's binary_logloss: 0.0797677\n",
      "[53]\ttraining's auc: 0.819253\ttraining's binary_logloss: 0.0789426\tvalid_1's auc: 0.78691\tvalid_1's binary_logloss: 0.0797747\n",
      "[54]\ttraining's auc: 0.819314\ttraining's binary_logloss: 0.0789076\tvalid_1's auc: 0.786886\tvalid_1's binary_logloss: 0.0797468\n",
      "[55]\ttraining's auc: 0.819596\ttraining's binary_logloss: 0.0788797\tvalid_1's auc: 0.787097\tvalid_1's binary_logloss: 0.0797247\n",
      "[56]\ttraining's auc: 0.819635\ttraining's binary_logloss: 0.078849\tvalid_1's auc: 0.78727\tvalid_1's binary_logloss: 0.0797196\n",
      "[57]\ttraining's auc: 0.819524\ttraining's binary_logloss: 0.0788176\tvalid_1's auc: 0.787202\tvalid_1's binary_logloss: 0.0797061\n",
      "[58]\ttraining's auc: 0.819885\ttraining's binary_logloss: 0.0787809\tvalid_1's auc: 0.786986\tvalid_1's binary_logloss: 0.0796773\n",
      "[59]\ttraining's auc: 0.820132\ttraining's binary_logloss: 0.0787563\tvalid_1's auc: 0.787051\tvalid_1's binary_logloss: 0.0796595\n",
      "[60]\ttraining's auc: 0.820314\ttraining's binary_logloss: 0.0787336\tvalid_1's auc: 0.787165\tvalid_1's binary_logloss: 0.0796406\n",
      "[61]\ttraining's auc: 0.820354\ttraining's binary_logloss: 0.0787033\tvalid_1's auc: 0.786894\tvalid_1's binary_logloss: 0.079616\n",
      "[62]\ttraining's auc: 0.820356\ttraining's binary_logloss: 0.078681\tvalid_1's auc: 0.786521\tvalid_1's binary_logloss: 0.0795994\n",
      "[63]\ttraining's auc: 0.820373\ttraining's binary_logloss: 0.0786642\tvalid_1's auc: 0.786666\tvalid_1's binary_logloss: 0.0795999\n",
      "[64]\ttraining's auc: 0.820427\ttraining's binary_logloss: 0.0786379\tvalid_1's auc: 0.786603\tvalid_1's binary_logloss: 0.0795844\n",
      "[65]\ttraining's auc: 0.820394\ttraining's binary_logloss: 0.078617\tvalid_1's auc: 0.786761\tvalid_1's binary_logloss: 0.0795779\n",
      "[66]\ttraining's auc: 0.820447\ttraining's binary_logloss: 0.0785933\tvalid_1's auc: 0.786886\tvalid_1's binary_logloss: 0.0795861\n",
      "[67]\ttraining's auc: 0.820571\ttraining's binary_logloss: 0.0785753\tvalid_1's auc: 0.786924\tvalid_1's binary_logloss: 0.0795749\n",
      "[68]\ttraining's auc: 0.82087\ttraining's binary_logloss: 0.0785515\tvalid_1's auc: 0.786913\tvalid_1's binary_logloss: 0.0795443\n",
      "[69]\ttraining's auc: 0.820836\ttraining's binary_logloss: 0.0785265\tvalid_1's auc: 0.787007\tvalid_1's binary_logloss: 0.0795287\n",
      "[70]\ttraining's auc: 0.820941\ttraining's binary_logloss: 0.07851\tvalid_1's auc: 0.787047\tvalid_1's binary_logloss: 0.0795128\n",
      "[71]\ttraining's auc: 0.821038\ttraining's binary_logloss: 0.0784937\tvalid_1's auc: 0.787206\tvalid_1's binary_logloss: 0.0794998\n",
      "[72]\ttraining's auc: 0.821196\ttraining's binary_logloss: 0.0784731\tvalid_1's auc: 0.787411\tvalid_1's binary_logloss: 0.0794832\n",
      "[73]\ttraining's auc: 0.821244\ttraining's binary_logloss: 0.0784582\tvalid_1's auc: 0.787389\tvalid_1's binary_logloss: 0.079457\n",
      "[74]\ttraining's auc: 0.821283\ttraining's binary_logloss: 0.0784464\tvalid_1's auc: 0.787436\tvalid_1's binary_logloss: 0.0794639\n",
      "[75]\ttraining's auc: 0.821328\ttraining's binary_logloss: 0.0784297\tvalid_1's auc: 0.787239\tvalid_1's binary_logloss: 0.0794601\n",
      "[76]\ttraining's auc: 0.821475\ttraining's binary_logloss: 0.0784187\tvalid_1's auc: 0.787371\tvalid_1's binary_logloss: 0.0794386\n",
      "[77]\ttraining's auc: 0.821516\ttraining's binary_logloss: 0.0784014\tvalid_1's auc: 0.787178\tvalid_1's binary_logloss: 0.0794354\n",
      "[78]\ttraining's auc: 0.821563\ttraining's binary_logloss: 0.0783877\tvalid_1's auc: 0.78719\tvalid_1's binary_logloss: 0.0794215\n",
      "[79]\ttraining's auc: 0.821637\ttraining's binary_logloss: 0.0783782\tvalid_1's auc: 0.787271\tvalid_1's binary_logloss: 0.0794005\n",
      "[80]\ttraining's auc: 0.82165\ttraining's binary_logloss: 0.0783677\tvalid_1's auc: 0.787199\tvalid_1's binary_logloss: 0.0794142\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[80]\ttraining's auc: 0.82165\ttraining's binary_logloss: 0.0783677\tvalid_1's auc: 0.787199\tvalid_1's binary_logloss: 0.0794142\n",
      "8\n",
      "train_ks:  0.4912095510164427\n",
      "test_ks:  0.47308659192151115\n",
      "ft_lst:  ['credit_info', 'act_info', 'person_info', 'finance_info']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_lst = {}\n",
    "ks_train_lst = []\n",
    "ks_test_lst = []\n",
    "for rk in set(df_train['rank']):   \n",
    "    \n",
    "    # 测试集8.18以后作为跨时间验证集\n",
    "    \n",
    "    #定义模型训练集与测试集\n",
    "    #在第一轮，rank为1的作为测试集，其他4份为训练集，for循环5次进行5轮\n",
    "    ttest = df_train[df_train['rank'] ==  rk]\n",
    "    ttrain = df_train[df_train['rank'] !=  rk]\n",
    "    \n",
    "    train = ttrain[lst]\n",
    "    train_y = ttrain.bad_ind\n",
    "    \n",
    "    test = ttest[lst]\n",
    "    test_y = ttest.bad_ind    \n",
    "    \n",
    "    start = time.time()\n",
    "    model,auc = LGB_test(train,train_y,test,test_y)                    \n",
    "    end = time.time()\n",
    "    \n",
    "    #模型贡献度放在feature中\n",
    "    feature = pd.DataFrame(\n",
    "                {'name' : model.booster_.feature_name(),\n",
    "                'importance' : model.feature_importances_\n",
    "              }).sort_values(by =  ['importance'],ascending = False)\n",
    "    #print(feature)\n",
    "    \n",
    "       \n",
    "    #计算训练集、测试集、验证集上的KS和AUC\n",
    "\n",
    "    y_pred_train_lgb = model.predict_proba(train)[:, 1]\n",
    "    y_pred_test_lgb = model.predict_proba(test)[:, 1]\n",
    "\n",
    "\n",
    "    train_fpr_lgb, train_tpr_lgb, _ = roc_curve(train_y, y_pred_train_lgb)\n",
    "    test_fpr_lgb, test_tpr_lgb, _ = roc_curve(test_y, y_pred_test_lgb)\n",
    "\n",
    "\n",
    "    train_ks = abs(train_fpr_lgb - train_tpr_lgb).max()\n",
    "    test_ks = abs(test_fpr_lgb - test_tpr_lgb).max()\n",
    "\n",
    "\n",
    "    train_auc = metrics.auc(train_fpr_lgb, train_tpr_lgb)\n",
    "    test_auc = metrics.auc(test_fpr_lgb, test_tpr_lgb)\n",
    "    \n",
    "    ks_train_lst.append(train_ks)\n",
    "    ks_test_lst.append(test_ks)    \n",
    "\n",
    "    feature_lst[str(rk)] = feature[feature.importance>=20].name\n",
    "\n",
    "train_ks = np.mean(ks_train_lst)\n",
    "test_ks = np.mean(ks_test_lst)\n",
    "\n",
    "ft_lst = {}\n",
    "for i in range(1,6):\n",
    "    ft_lst[str(i)] = feature_lst[str(i)]\n",
    "#print(feature_lst)\n",
    "#5轮重要特征取交集\n",
    "fn_lst=list(set(ft_lst['1']) & set(ft_lst['2'])& set(ft_lst['3']) & set(ft_lst['4']) &set(ft_lst['5']))\n",
    "\n",
    "print('train_ks: ',train_ks)\n",
    "print('test_ks: ',test_ks)\n",
    "\n",
    "print('ft_lst: ',fn_lst )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacquelin/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.735642\ttraining's binary_logloss: 0.091006\tvalid_1's auc: 0.724797\tvalid_1's binary_logloss: 0.0992666\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.789312\ttraining's binary_logloss: 0.0896377\tvalid_1's auc: 0.764213\tvalid_1's binary_logloss: 0.0978427\n",
      "[3]\ttraining's auc: 0.791924\ttraining's binary_logloss: 0.0883854\tvalid_1's auc: 0.767788\tvalid_1's binary_logloss: 0.0964733\n",
      "[4]\ttraining's auc: 0.792844\ttraining's binary_logloss: 0.0874345\tvalid_1's auc: 0.767467\tvalid_1's binary_logloss: 0.0954996\n",
      "[5]\ttraining's auc: 0.792178\ttraining's binary_logloss: 0.0866018\tvalid_1's auc: 0.768703\tvalid_1's binary_logloss: 0.0946422\n",
      "[6]\ttraining's auc: 0.793624\ttraining's binary_logloss: 0.0861442\tvalid_1's auc: 0.770601\tvalid_1's binary_logloss: 0.0941544\n",
      "[7]\ttraining's auc: 0.793346\ttraining's binary_logloss: 0.0857377\tvalid_1's auc: 0.771983\tvalid_1's binary_logloss: 0.0937597\n",
      "[8]\ttraining's auc: 0.793341\ttraining's binary_logloss: 0.085167\tvalid_1's auc: 0.771216\tvalid_1's binary_logloss: 0.0931981\n",
      "[9]\ttraining's auc: 0.794779\ttraining's binary_logloss: 0.0846254\tvalid_1's auc: 0.772071\tvalid_1's binary_logloss: 0.0927045\n",
      "[10]\ttraining's auc: 0.794834\ttraining's binary_logloss: 0.0841666\tvalid_1's auc: 0.770631\tvalid_1's binary_logloss: 0.0923098\n",
      "[11]\ttraining's auc: 0.794264\ttraining's binary_logloss: 0.0837648\tvalid_1's auc: 0.769889\tvalid_1's binary_logloss: 0.0919377\n",
      "[12]\ttraining's auc: 0.79521\ttraining's binary_logloss: 0.0834012\tvalid_1's auc: 0.769066\tvalid_1's binary_logloss: 0.091738\n",
      "[13]\ttraining's auc: 0.795665\ttraining's binary_logloss: 0.0831308\tvalid_1's auc: 0.770137\tvalid_1's binary_logloss: 0.0914969\n",
      "[14]\ttraining's auc: 0.796174\ttraining's binary_logloss: 0.0827946\tvalid_1's auc: 0.770225\tvalid_1's binary_logloss: 0.0912668\n",
      "[15]\ttraining's auc: 0.79862\ttraining's binary_logloss: 0.0825094\tvalid_1's auc: 0.770667\tvalid_1's binary_logloss: 0.0911258\n",
      "[16]\ttraining's auc: 0.798892\ttraining's binary_logloss: 0.0823076\tvalid_1's auc: 0.771421\tvalid_1's binary_logloss: 0.0909608\n",
      "[17]\ttraining's auc: 0.798888\ttraining's binary_logloss: 0.0820609\tvalid_1's auc: 0.771403\tvalid_1's binary_logloss: 0.0908082\n",
      "[18]\ttraining's auc: 0.799098\ttraining's binary_logloss: 0.0818541\tvalid_1's auc: 0.770415\tvalid_1's binary_logloss: 0.0906953\n",
      "[19]\ttraining's auc: 0.799163\ttraining's binary_logloss: 0.0816481\tvalid_1's auc: 0.769726\tvalid_1's binary_logloss: 0.0905757\n",
      "[20]\ttraining's auc: 0.803362\ttraining's binary_logloss: 0.0814729\tvalid_1's auc: 0.773163\tvalid_1's binary_logloss: 0.0905321\n",
      "[21]\ttraining's auc: 0.803659\ttraining's binary_logloss: 0.0813116\tvalid_1's auc: 0.774036\tvalid_1's binary_logloss: 0.0904301\n",
      "[22]\ttraining's auc: 0.803994\ttraining's binary_logloss: 0.0811451\tvalid_1's auc: 0.774366\tvalid_1's binary_logloss: 0.0903257\n",
      "[23]\ttraining's auc: 0.803974\ttraining's binary_logloss: 0.0809984\tvalid_1's auc: 0.77448\tvalid_1's binary_logloss: 0.0902511\n",
      "[24]\ttraining's auc: 0.804677\ttraining's binary_logloss: 0.0808671\tvalid_1's auc: 0.774965\tvalid_1's binary_logloss: 0.0902028\n",
      "[25]\ttraining's auc: 0.805591\ttraining's binary_logloss: 0.0807398\tvalid_1's auc: 0.774923\tvalid_1's binary_logloss: 0.0901661\n",
      "[26]\ttraining's auc: 0.805647\ttraining's binary_logloss: 0.0806188\tvalid_1's auc: 0.77482\tvalid_1's binary_logloss: 0.0901076\n",
      "[27]\ttraining's auc: 0.805652\ttraining's binary_logloss: 0.0805122\tvalid_1's auc: 0.774634\tvalid_1's binary_logloss: 0.0900855\n",
      "[28]\ttraining's auc: 0.806195\ttraining's binary_logloss: 0.080407\tvalid_1's auc: 0.775169\tvalid_1's binary_logloss: 0.09003\n",
      "[29]\ttraining's auc: 0.806167\ttraining's binary_logloss: 0.0803116\tvalid_1's auc: 0.775099\tvalid_1's binary_logloss: 0.0899891\n",
      "[30]\ttraining's auc: 0.806485\ttraining's binary_logloss: 0.0802232\tvalid_1's auc: 0.774616\tvalid_1's binary_logloss: 0.0899876\n",
      "[31]\ttraining's auc: 0.80664\ttraining's binary_logloss: 0.0801454\tvalid_1's auc: 0.774306\tvalid_1's binary_logloss: 0.0899555\n",
      "[32]\ttraining's auc: 0.806855\ttraining's binary_logloss: 0.0800657\tvalid_1's auc: 0.774204\tvalid_1's binary_logloss: 0.0899398\n",
      "[33]\ttraining's auc: 0.807553\ttraining's binary_logloss: 0.0799835\tvalid_1's auc: 0.77532\tvalid_1's binary_logloss: 0.0898903\n",
      "[34]\ttraining's auc: 0.807717\ttraining's binary_logloss: 0.0799077\tvalid_1's auc: 0.775424\tvalid_1's binary_logloss: 0.0898765\n",
      "[35]\ttraining's auc: 0.807531\ttraining's binary_logloss: 0.0798472\tvalid_1's auc: 0.774769\tvalid_1's binary_logloss: 0.0898603\n",
      "[36]\ttraining's auc: 0.808125\ttraining's binary_logloss: 0.079768\tvalid_1's auc: 0.775159\tvalid_1's binary_logloss: 0.0898276\n",
      "[37]\ttraining's auc: 0.808251\ttraining's binary_logloss: 0.0797017\tvalid_1's auc: 0.775593\tvalid_1's binary_logloss: 0.0897936\n",
      "[38]\ttraining's auc: 0.808479\ttraining's binary_logloss: 0.0796336\tvalid_1's auc: 0.776075\tvalid_1's binary_logloss: 0.0897556\n",
      "[39]\ttraining's auc: 0.808716\ttraining's binary_logloss: 0.0795827\tvalid_1's auc: 0.77631\tvalid_1's binary_logloss: 0.0897423\n",
      "[40]\ttraining's auc: 0.808926\ttraining's binary_logloss: 0.0795176\tvalid_1's auc: 0.776831\tvalid_1's binary_logloss: 0.0897215\n",
      "[41]\ttraining's auc: 0.809254\ttraining's binary_logloss: 0.079462\tvalid_1's auc: 0.777973\tvalid_1's binary_logloss: 0.0897075\n",
      "[42]\ttraining's auc: 0.809689\ttraining's binary_logloss: 0.0794063\tvalid_1's auc: 0.77825\tvalid_1's binary_logloss: 0.0896934\n",
      "[43]\ttraining's auc: 0.81049\ttraining's binary_logloss: 0.0793567\tvalid_1's auc: 0.77857\tvalid_1's binary_logloss: 0.089686\n",
      "[44]\ttraining's auc: 0.810653\ttraining's binary_logloss: 0.0793081\tvalid_1's auc: 0.778543\tvalid_1's binary_logloss: 0.089676\n",
      "[45]\ttraining's auc: 0.810797\ttraining's binary_logloss: 0.0792635\tvalid_1's auc: 0.778764\tvalid_1's binary_logloss: 0.0896744\n",
      "[46]\ttraining's auc: 0.810932\ttraining's binary_logloss: 0.0792162\tvalid_1's auc: 0.779108\tvalid_1's binary_logloss: 0.0896529\n",
      "[47]\ttraining's auc: 0.810856\ttraining's binary_logloss: 0.0791777\tvalid_1's auc: 0.779021\tvalid_1's binary_logloss: 0.0896536\n",
      "[48]\ttraining's auc: 0.810976\ttraining's binary_logloss: 0.0791369\tvalid_1's auc: 0.779259\tvalid_1's binary_logloss: 0.0896508\n",
      "[49]\ttraining's auc: 0.810968\ttraining's binary_logloss: 0.0790954\tvalid_1's auc: 0.779459\tvalid_1's binary_logloss: 0.0896327\n",
      "[50]\ttraining's auc: 0.811257\ttraining's binary_logloss: 0.0790656\tvalid_1's auc: 0.779595\tvalid_1's binary_logloss: 0.0896238\n",
      "[51]\ttraining's auc: 0.811231\ttraining's binary_logloss: 0.0790293\tvalid_1's auc: 0.779483\tvalid_1's binary_logloss: 0.089605\n",
      "[52]\ttraining's auc: 0.811464\ttraining's binary_logloss: 0.0789987\tvalid_1's auc: 0.779611\tvalid_1's binary_logloss: 0.0896166\n",
      "[53]\ttraining's auc: 0.811547\ttraining's binary_logloss: 0.0789747\tvalid_1's auc: 0.779759\tvalid_1's binary_logloss: 0.0896212\n",
      "[54]\ttraining's auc: 0.811633\ttraining's binary_logloss: 0.0789436\tvalid_1's auc: 0.779784\tvalid_1's binary_logloss: 0.089634\n",
      "[55]\ttraining's auc: 0.811736\ttraining's binary_logloss: 0.0789107\tvalid_1's auc: 0.780026\tvalid_1's binary_logloss: 0.0896273\n",
      "[56]\ttraining's auc: 0.811823\ttraining's binary_logloss: 0.0788865\tvalid_1's auc: 0.779952\tvalid_1's binary_logloss: 0.0896221\n",
      "[57]\ttraining's auc: 0.81207\ttraining's binary_logloss: 0.0788561\tvalid_1's auc: 0.780186\tvalid_1's binary_logloss: 0.0896389\n",
      "[58]\ttraining's auc: 0.812311\ttraining's binary_logloss: 0.0788334\tvalid_1's auc: 0.780364\tvalid_1's binary_logloss: 0.0896437\n",
      "[59]\ttraining's auc: 0.812273\ttraining's binary_logloss: 0.0788084\tvalid_1's auc: 0.780111\tvalid_1's binary_logloss: 0.0896445\n",
      "[60]\ttraining's auc: 0.812451\ttraining's binary_logloss: 0.0787819\tvalid_1's auc: 0.779966\tvalid_1's binary_logloss: 0.0896653\n",
      "[61]\ttraining's auc: 0.812473\ttraining's binary_logloss: 0.0787663\tvalid_1's auc: 0.779951\tvalid_1's binary_logloss: 0.0896842\n",
      "[62]\ttraining's auc: 0.812677\ttraining's binary_logloss: 0.0787472\tvalid_1's auc: 0.779984\tvalid_1's binary_logloss: 0.0896922\n",
      "[63]\ttraining's auc: 0.812805\ttraining's binary_logloss: 0.0787266\tvalid_1's auc: 0.779902\tvalid_1's binary_logloss: 0.089691\n",
      "[64]\ttraining's auc: 0.812784\ttraining's binary_logloss: 0.0787097\tvalid_1's auc: 0.780122\tvalid_1's binary_logloss: 0.0897092\n",
      "[65]\ttraining's auc: 0.812833\ttraining's binary_logloss: 0.0786892\tvalid_1's auc: 0.780128\tvalid_1's binary_logloss: 0.0897241\n",
      "[66]\ttraining's auc: 0.812899\ttraining's binary_logloss: 0.0786657\tvalid_1's auc: 0.78033\tvalid_1's binary_logloss: 0.089723\n",
      "[67]\ttraining's auc: 0.812884\ttraining's binary_logloss: 0.0786497\tvalid_1's auc: 0.780292\tvalid_1's binary_logloss: 0.0897409\n",
      "[68]\ttraining's auc: 0.812924\ttraining's binary_logloss: 0.0786382\tvalid_1's auc: 0.780286\tvalid_1's binary_logloss: 0.089754\n",
      "[69]\ttraining's auc: 0.812888\ttraining's binary_logloss: 0.0786239\tvalid_1's auc: 0.779924\tvalid_1's binary_logloss: 0.0897694\n",
      "[70]\ttraining's auc: 0.813106\ttraining's binary_logloss: 0.0786086\tvalid_1's auc: 0.780074\tvalid_1's binary_logloss: 0.0897635\n",
      "[71]\ttraining's auc: 0.813223\ttraining's binary_logloss: 0.0785982\tvalid_1's auc: 0.779847\tvalid_1's binary_logloss: 0.0897564\n",
      "[72]\ttraining's auc: 0.813321\ttraining's binary_logloss: 0.0785853\tvalid_1's auc: 0.779949\tvalid_1's binary_logloss: 0.0897522\n",
      "[73]\ttraining's auc: 0.813233\ttraining's binary_logloss: 0.0785718\tvalid_1's auc: 0.779988\tvalid_1's binary_logloss: 0.0897371\n",
      "[74]\ttraining's auc: 0.813344\ttraining's binary_logloss: 0.0785568\tvalid_1's auc: 0.779639\tvalid_1's binary_logloss: 0.0897389\n",
      "[75]\ttraining's auc: 0.813413\ttraining's binary_logloss: 0.0785469\tvalid_1's auc: 0.779609\tvalid_1's binary_logloss: 0.0897376\n",
      "[76]\ttraining's auc: 0.813473\ttraining's binary_logloss: 0.0785395\tvalid_1's auc: 0.779676\tvalid_1's binary_logloss: 0.0897388\n",
      "[77]\ttraining's auc: 0.813543\ttraining's binary_logloss: 0.0785315\tvalid_1's auc: 0.779641\tvalid_1's binary_logloss: 0.0897459\n",
      "[78]\ttraining's auc: 0.813595\ttraining's binary_logloss: 0.07851\tvalid_1's auc: 0.779739\tvalid_1's binary_logloss: 0.0897273\n",
      "[79]\ttraining's auc: 0.813583\ttraining's binary_logloss: 0.078498\tvalid_1's auc: 0.779769\tvalid_1's binary_logloss: 0.0897677\n",
      "[80]\ttraining's auc: 0.813663\ttraining's binary_logloss: 0.0784894\tvalid_1's auc: 0.779814\tvalid_1's binary_logloss: 0.0897736\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[80]\ttraining's auc: 0.813663\ttraining's binary_logloss: 0.0784894\tvalid_1's auc: 0.779814\tvalid_1's binary_logloss: 0.0897736\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ks :  0.48729706147207924\n",
      "evl_ks :  0.43312693775943956\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lst = ['person_info','finance_info','credit_info','act_info']\n",
    "\n",
    "train = data[data.obs_mth != '2018-11-30'].reset_index().copy()\n",
    "evl = data[data.obs_mth == '2018-11-30'].reset_index().copy()\n",
    "\n",
    "x = train[lst]\n",
    "y = train['bad_ind']\n",
    "\n",
    "evl_x =  evl[lst]\n",
    "evl_y = evl['bad_ind']\n",
    "\n",
    "model,auc = LGB_test(x,y,evl_x,evl_y)\n",
    "\n",
    "y_pred = model.predict_proba(x)[:,1]\n",
    "fpr_lgb_train,tpr_lgb_train,_ = roc_curve(y,y_pred)\n",
    "train_ks = abs(fpr_lgb_train - tpr_lgb_train).max()\n",
    "print('train_ks : ',train_ks)\n",
    "\n",
    "y_pred = model.predict_proba(evl_x)[:,1]\n",
    "fpr_lgb,tpr_lgb,_ = roc_curve(evl_y,y_pred)\n",
    "evl_ks = abs(fpr_lgb - tpr_lgb).max()\n",
    "print('evl_ks : ',evl_ks)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(fpr_lgb_train,tpr_lgb_train,label = 'train LR')\n",
    "plt.plot(fpr_lgb,tpr_lgb,label = 'evl LR')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['person_info','finance_info','credit_info','act_info']\n",
    "#算分数onekey \n",
    "def score(xbeta):\n",
    "    score = 1000-500*(math.log2(1-xbeta)/xbeta)  #好人的概率/坏人的概率\n",
    "    return score\n",
    "evl['xbeta'] = model.predict_proba(evl_x)[:,1]   \n",
    "evl['score'] = evl.apply(lambda x : score(x.xbeta) ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_ks :  0.43312693775943956\n"
     ]
    }
   ],
   "source": [
    "fpr_lr,tpr_lr,_ = roc_curve(evl_y,evl['score'])\n",
    "evl_ks = abs(fpr_lr - tpr_lr).max()\n",
    "print('val_ks : ',evl_ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KS</th>\n",
       "      <th>BAD</th>\n",
       "      <th>GOOD</th>\n",
       "      <th>BAD_CNT</th>\n",
       "      <th>GOOD_CNT</th>\n",
       "      <th>BAD_PCTG</th>\n",
       "      <th>BADRATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.235</td>\n",
       "      <td>92</td>\n",
       "      <td>707</td>\n",
       "      <td>92</td>\n",
       "      <td>707</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.299</td>\n",
       "      <td>37</td>\n",
       "      <td>762</td>\n",
       "      <td>129</td>\n",
       "      <td>1469</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.336</td>\n",
       "      <td>28</td>\n",
       "      <td>771</td>\n",
       "      <td>157</td>\n",
       "      <td>2240</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.393</td>\n",
       "      <td>35</td>\n",
       "      <td>764</td>\n",
       "      <td>192</td>\n",
       "      <td>3004</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.398</td>\n",
       "      <td>18</td>\n",
       "      <td>781</td>\n",
       "      <td>210</td>\n",
       "      <td>3785</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.419</td>\n",
       "      <td>23</td>\n",
       "      <td>776</td>\n",
       "      <td>233</td>\n",
       "      <td>4561</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.421</td>\n",
       "      <td>17</td>\n",
       "      <td>782</td>\n",
       "      <td>250</td>\n",
       "      <td>5343</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.404</td>\n",
       "      <td>11</td>\n",
       "      <td>788</td>\n",
       "      <td>261</td>\n",
       "      <td>6131</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.381</td>\n",
       "      <td>9</td>\n",
       "      <td>790</td>\n",
       "      <td>270</td>\n",
       "      <td>6921</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.370</td>\n",
       "      <td>13</td>\n",
       "      <td>786</td>\n",
       "      <td>283</td>\n",
       "      <td>7707</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.363</td>\n",
       "      <td>14</td>\n",
       "      <td>785</td>\n",
       "      <td>297</td>\n",
       "      <td>8492</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.321</td>\n",
       "      <td>3</td>\n",
       "      <td>796</td>\n",
       "      <td>300</td>\n",
       "      <td>9288</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.292</td>\n",
       "      <td>7</td>\n",
       "      <td>792</td>\n",
       "      <td>307</td>\n",
       "      <td>10080</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.250</td>\n",
       "      <td>3</td>\n",
       "      <td>796</td>\n",
       "      <td>310</td>\n",
       "      <td>10876</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.215</td>\n",
       "      <td>5</td>\n",
       "      <td>794</td>\n",
       "      <td>315</td>\n",
       "      <td>11670</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.185</td>\n",
       "      <td>7</td>\n",
       "      <td>792</td>\n",
       "      <td>322</td>\n",
       "      <td>12462</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.137</td>\n",
       "      <td>1</td>\n",
       "      <td>798</td>\n",
       "      <td>323</td>\n",
       "      <td>13260</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.089</td>\n",
       "      <td>1</td>\n",
       "      <td>798</td>\n",
       "      <td>324</td>\n",
       "      <td>14058</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.048</td>\n",
       "      <td>3</td>\n",
       "      <td>796</td>\n",
       "      <td>327</td>\n",
       "      <td>14854</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>793</td>\n",
       "      <td>328</td>\n",
       "      <td>15647</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       KS  BAD  GOOD  BAD_CNT  GOOD_CNT  BAD_PCTG  BADRATE\n",
       "0   0.235   92   707       92       707     0.280    0.115\n",
       "1   0.299   37   762      129      1469     0.393    0.046\n",
       "2   0.336   28   771      157      2240     0.479    0.035\n",
       "3   0.393   35   764      192      3004     0.585    0.044\n",
       "4   0.398   18   781      210      3785     0.640    0.023\n",
       "5   0.419   23   776      233      4561     0.710    0.029\n",
       "6   0.421   17   782      250      5343     0.762    0.021\n",
       "7   0.404   11   788      261      6131     0.796    0.014\n",
       "8   0.381    9   790      270      6921     0.823    0.011\n",
       "9   0.370   13   786      283      7707     0.863    0.016\n",
       "10  0.363   14   785      297      8492     0.905    0.018\n",
       "11  0.321    3   796      300      9288     0.915    0.004\n",
       "12  0.292    7   792      307     10080     0.936    0.009\n",
       "13  0.250    3   796      310     10876     0.945    0.004\n",
       "14  0.215    5   794      315     11670     0.960    0.006\n",
       "15  0.185    7   792      322     12462     0.982    0.009\n",
       "16  0.137    1   798      323     13260     0.985    0.001\n",
       "17  0.089    1   798      324     14058     0.988    0.001\n",
       "18  0.048    3   796      327     14854     0.997    0.004\n",
       "19  0.000    1   793      328     15647     1.000    0.001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#生成报告\n",
    "row_num, col_num = 0, 0\n",
    "bins = 20\n",
    "Y_predict = evl['score']\n",
    "Y = evl_y\n",
    "nrows = Y.shape[0]\n",
    "lis = [(Y_predict[i], Y[i]) for i in range(nrows)]\n",
    "ks_lis = sorted(lis, key=lambda x: x[0], reverse=True)\n",
    "bin_num = int(nrows/bins+1)\n",
    "bad = sum([1 for (p, y) in ks_lis if y > 0.5])\n",
    "good = sum([1 for (p, y) in ks_lis if y <= 0.5])\n",
    "bad_cnt, good_cnt = 0, 0\n",
    "KS = []\n",
    "BAD = []\n",
    "GOOD = []\n",
    "BAD_CNT = []\n",
    "GOOD_CNT = []\n",
    "BAD_PCTG = []\n",
    "BADRATE = []\n",
    "dct_report = {}\n",
    "for j in range(bins):\n",
    "    ds = ks_lis[j*bin_num: min((j+1)*bin_num, nrows)]\n",
    "    bad1 = sum([1 for (p, y) in ds if y > 0.5])\n",
    "    good1 = sum([1 for (p, y) in ds if y <= 0.5])\n",
    "    bad_cnt += bad1\n",
    "    good_cnt += good1\n",
    "    bad_pctg = round(bad_cnt/sum(evl_y),3)\n",
    "    badrate = round(bad1/(bad1+good1),3)\n",
    "    ks = round(math.fabs((bad_cnt / bad) - (good_cnt / good)),3)\n",
    "    KS.append(ks)\n",
    "    BAD.append(bad1)\n",
    "    GOOD.append(good1)\n",
    "    BAD_CNT.append(bad_cnt)\n",
    "    GOOD_CNT.append(good_cnt)\n",
    "    BAD_PCTG.append(bad_pctg)\n",
    "    BADRATE.append(badrate)\n",
    "    dct_report['KS'] = KS\n",
    "    dct_report['BAD'] = BAD\n",
    "    dct_report['GOOD'] = GOOD\n",
    "    dct_report['BAD_CNT'] = BAD_CNT\n",
    "    dct_report['GOOD_CNT'] = GOOD_CNT\n",
    "    dct_report['BAD_PCTG'] = BAD_PCTG\n",
    "    dct_report['BADRATE'] = BADRATE\n",
    "val_repot = pd.DataFrame(dct_report)\n",
    "val_repot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "    require.config({\n",
       "        paths: {\n",
       "            'echarts':'https://assets.pyecharts.org/assets/echarts.min'\n",
       "        }\n",
       "    });\n",
       "</script>\n",
       "\n",
       "        <div id=\"ea8e84a85e3d497f9c4a997ebd29cb82\" style=\"width:900px; height:500px;\"></div>\n",
       "\n",
       "<script>\n",
       "        require(['echarts'], function(echarts) {\n",
       "                var chart_ea8e84a85e3d497f9c4a997ebd29cb82 = echarts.init(\n",
       "                    document.getElementById('ea8e84a85e3d497f9c4a997ebd29cb82'), 'white', {renderer: 'canvas'});\n",
       "                var option_ea8e84a85e3d497f9c4a997ebd29cb82 = {\n",
       "    \"animation\": true,\n",
       "    \"animationThreshold\": 2000,\n",
       "    \"animationDuration\": 1000,\n",
       "    \"animationEasing\": \"cubicOut\",\n",
       "    \"animationDelay\": 0,\n",
       "    \"animationDurationUpdate\": 300,\n",
       "    \"animationEasingUpdate\": \"cubicOut\",\n",
       "    \"animationDelayUpdate\": 0,\n",
       "    \"color\": [\n",
       "        \"blue\",\n",
       "        \"red\",\n",
       "        \"#c23531\",\n",
       "        \"#2f4554\",\n",
       "        \"#61a0a8\",\n",
       "        \"#d48265\",\n",
       "        \"#749f83\",\n",
       "        \"#ca8622\",\n",
       "        \"#bda29a\",\n",
       "        \"#6e7074\",\n",
       "        \"#546570\",\n",
       "        \"#c4ccd3\",\n",
       "        \"#f05b72\",\n",
       "        \"#ef5b9c\",\n",
       "        \"#f47920\",\n",
       "        \"#905a3d\",\n",
       "        \"#fab27b\",\n",
       "        \"#2a5caa\",\n",
       "        \"#444693\",\n",
       "        \"#726930\",\n",
       "        \"#b2d235\",\n",
       "        \"#6d8346\",\n",
       "        \"#ac6767\",\n",
       "        \"#1d953f\",\n",
       "        \"#6950a1\",\n",
       "        \"#918597\"\n",
       "    ],\n",
       "    \"series\": [\n",
       "        {\n",
       "            \"type\": \"line\",\n",
       "            \"name\": \"\\u5206\\u7ec4\\u574f\\u4eba\\u5360\\u6bd4\",\n",
       "            \"connectNulls\": false,\n",
       "            \"yAxisIndex\": 0,\n",
       "            \"symbolSize\": 4,\n",
       "            \"showSymbol\": true,\n",
       "            \"smooth\": false,\n",
       "            \"step\": false,\n",
       "            \"data\": [\n",
       "                [\n",
       "                    0,\n",
       "                    0.115\n",
       "                ],\n",
       "                [\n",
       "                    1,\n",
       "                    0.046\n",
       "                ],\n",
       "                [\n",
       "                    2,\n",
       "                    0.035\n",
       "                ],\n",
       "                [\n",
       "                    3,\n",
       "                    0.044\n",
       "                ],\n",
       "                [\n",
       "                    4,\n",
       "                    0.023\n",
       "                ],\n",
       "                [\n",
       "                    5,\n",
       "                    0.029\n",
       "                ],\n",
       "                [\n",
       "                    6,\n",
       "                    0.021\n",
       "                ],\n",
       "                [\n",
       "                    7,\n",
       "                    0.014\n",
       "                ],\n",
       "                [\n",
       "                    8,\n",
       "                    0.011\n",
       "                ],\n",
       "                [\n",
       "                    9,\n",
       "                    0.016\n",
       "                ],\n",
       "                [\n",
       "                    10,\n",
       "                    0.018\n",
       "                ],\n",
       "                [\n",
       "                    11,\n",
       "                    0.004\n",
       "                ],\n",
       "                [\n",
       "                    12,\n",
       "                    0.009\n",
       "                ],\n",
       "                [\n",
       "                    13,\n",
       "                    0.004\n",
       "                ],\n",
       "                [\n",
       "                    14,\n",
       "                    0.006\n",
       "                ],\n",
       "                [\n",
       "                    15,\n",
       "                    0.009\n",
       "                ],\n",
       "                [\n",
       "                    16,\n",
       "                    0.001\n",
       "                ],\n",
       "                [\n",
       "                    17,\n",
       "                    0.001\n",
       "                ],\n",
       "                [\n",
       "                    18,\n",
       "                    0.004\n",
       "                ],\n",
       "                [\n",
       "                    19,\n",
       "                    0.001\n",
       "                ]\n",
       "            ],\n",
       "            \"hoverAnimation\": true,\n",
       "            \"label\": {\n",
       "                \"show\": true,\n",
       "                \"position\": \"top\",\n",
       "                \"margin\": 8\n",
       "            },\n",
       "            \"lineStyle\": {\n",
       "                \"width\": 1,\n",
       "                \"opacity\": 1,\n",
       "                \"curveness\": 0,\n",
       "                \"type\": \"solid\"\n",
       "            },\n",
       "            \"areaStyle\": {\n",
       "                \"opacity\": 0\n",
       "            }\n",
       "        },\n",
       "        {\n",
       "            \"type\": \"line\",\n",
       "            \"name\": \"KS\",\n",
       "            \"connectNulls\": false,\n",
       "            \"yAxisIndex\": 1,\n",
       "            \"symbolSize\": 4,\n",
       "            \"showSymbol\": true,\n",
       "            \"smooth\": false,\n",
       "            \"step\": false,\n",
       "            \"data\": [\n",
       "                [\n",
       "                    0,\n",
       "                    0.235\n",
       "                ],\n",
       "                [\n",
       "                    1,\n",
       "                    0.299\n",
       "                ],\n",
       "                [\n",
       "                    2,\n",
       "                    0.336\n",
       "                ],\n",
       "                [\n",
       "                    3,\n",
       "                    0.393\n",
       "                ],\n",
       "                [\n",
       "                    4,\n",
       "                    0.398\n",
       "                ],\n",
       "                [\n",
       "                    5,\n",
       "                    0.419\n",
       "                ],\n",
       "                [\n",
       "                    6,\n",
       "                    0.421\n",
       "                ],\n",
       "                [\n",
       "                    7,\n",
       "                    0.404\n",
       "                ],\n",
       "                [\n",
       "                    8,\n",
       "                    0.381\n",
       "                ],\n",
       "                [\n",
       "                    9,\n",
       "                    0.37\n",
       "                ],\n",
       "                [\n",
       "                    10,\n",
       "                    0.363\n",
       "                ],\n",
       "                [\n",
       "                    11,\n",
       "                    0.321\n",
       "                ],\n",
       "                [\n",
       "                    12,\n",
       "                    0.292\n",
       "                ],\n",
       "                [\n",
       "                    13,\n",
       "                    0.25\n",
       "                ],\n",
       "                [\n",
       "                    14,\n",
       "                    0.215\n",
       "                ],\n",
       "                [\n",
       "                    15,\n",
       "                    0.185\n",
       "                ],\n",
       "                [\n",
       "                    16,\n",
       "                    0.137\n",
       "                ],\n",
       "                [\n",
       "                    17,\n",
       "                    0.089\n",
       "                ],\n",
       "                [\n",
       "                    18,\n",
       "                    0.048\n",
       "                ],\n",
       "                [\n",
       "                    19,\n",
       "                    0.0\n",
       "                ]\n",
       "            ],\n",
       "            \"hoverAnimation\": true,\n",
       "            \"label\": {\n",
       "                \"show\": false,\n",
       "                \"position\": \"top\",\n",
       "                \"margin\": 8\n",
       "            },\n",
       "            \"lineStyle\": {\n",
       "                \"width\": 1,\n",
       "                \"opacity\": 1,\n",
       "                \"curveness\": 0,\n",
       "                \"type\": \"solid\"\n",
       "            },\n",
       "            \"areaStyle\": {\n",
       "                \"opacity\": 0\n",
       "            }\n",
       "        }\n",
       "    ],\n",
       "    \"legend\": [\n",
       "        {\n",
       "            \"data\": [\n",
       "                \"\\u5206\\u7ec4\\u574f\\u4eba\\u5360\\u6bd4\",\n",
       "                \"KS\"\n",
       "            ],\n",
       "            \"selected\": {\n",
       "                \"\\u5206\\u7ec4\\u574f\\u4eba\\u5360\\u6bd4\": true,\n",
       "                \"KS\": true\n",
       "            },\n",
       "            \"show\": true\n",
       "        }\n",
       "    ],\n",
       "    \"tooltip\": {\n",
       "        \"show\": true,\n",
       "        \"trigger\": \"item\",\n",
       "        \"triggerOn\": \"mousemove|click\",\n",
       "        \"axisPointer\": {\n",
       "            \"type\": \"line\"\n",
       "        },\n",
       "        \"textStyle\": {\n",
       "            \"fontSize\": 14\n",
       "        },\n",
       "        \"borderWidth\": 0\n",
       "    },\n",
       "    \"xAxis\": [\n",
       "        {\n",
       "            \"show\": true,\n",
       "            \"scale\": false,\n",
       "            \"nameLocation\": \"end\",\n",
       "            \"nameGap\": 15,\n",
       "            \"gridIndex\": 0,\n",
       "            \"inverse\": false,\n",
       "            \"offset\": 0,\n",
       "            \"splitNumber\": 5,\n",
       "            \"minInterval\": 0,\n",
       "            \"splitLine\": {\n",
       "                \"show\": false,\n",
       "                \"lineStyle\": {\n",
       "                    \"width\": 1,\n",
       "                    \"opacity\": 1,\n",
       "                    \"curveness\": 0,\n",
       "                    \"type\": \"solid\"\n",
       "                }\n",
       "            },\n",
       "            \"data\": [\n",
       "                0,\n",
       "                1,\n",
       "                2,\n",
       "                3,\n",
       "                4,\n",
       "                5,\n",
       "                6,\n",
       "                7,\n",
       "                8,\n",
       "                9,\n",
       "                10,\n",
       "                11,\n",
       "                12,\n",
       "                13,\n",
       "                14,\n",
       "                15,\n",
       "                16,\n",
       "                17,\n",
       "                18,\n",
       "                19\n",
       "            ]\n",
       "        }\n",
       "    ],\n",
       "    \"yAxis\": [\n",
       "        {\n",
       "            \"show\": true,\n",
       "            \"scale\": false,\n",
       "            \"nameLocation\": \"end\",\n",
       "            \"nameGap\": 15,\n",
       "            \"gridIndex\": 0,\n",
       "            \"inverse\": false,\n",
       "            \"offset\": 0,\n",
       "            \"splitNumber\": 5,\n",
       "            \"minInterval\": 0,\n",
       "            \"splitLine\": {\n",
       "                \"show\": false,\n",
       "                \"lineStyle\": {\n",
       "                    \"width\": 1,\n",
       "                    \"opacity\": 1,\n",
       "                    \"curveness\": 0,\n",
       "                    \"type\": \"solid\"\n",
       "                }\n",
       "            }\n",
       "        },\n",
       "        {\n",
       "            \"type\": \"value\",\n",
       "            \"name\": \"\\u7d2f\\u8ba1\\u574f\\u4eba\\u5360\\u6bd4\",\n",
       "            \"show\": true,\n",
       "            \"scale\": false,\n",
       "            \"nameLocation\": \"end\",\n",
       "            \"nameGap\": 15,\n",
       "            \"gridIndex\": 0,\n",
       "            \"axisLine\": {\n",
       "                \"show\": true,\n",
       "                \"onZero\": true,\n",
       "                \"onZeroAxisIndex\": 0,\n",
       "                \"lineStyle\": {\n",
       "                    \"width\": 1,\n",
       "                    \"opacity\": 1,\n",
       "                    \"curveness\": 0,\n",
       "                    \"type\": \"solid\",\n",
       "                    \"color\": \"red\"\n",
       "                }\n",
       "            },\n",
       "            \"axisLabel\": {\n",
       "                \"show\": true,\n",
       "                \"position\": \"top\",\n",
       "                \"margin\": 8,\n",
       "                \"formatter\": \"{value}\"\n",
       "            },\n",
       "            \"inverse\": false,\n",
       "            \"position\": \"right\",\n",
       "            \"offset\": 0,\n",
       "            \"splitNumber\": 5,\n",
       "            \"min\": 0,\n",
       "            \"max\": 0.5,\n",
       "            \"minInterval\": 0,\n",
       "            \"splitLine\": {\n",
       "                \"show\": false,\n",
       "                \"lineStyle\": {\n",
       "                    \"width\": 1,\n",
       "                    \"opacity\": 1,\n",
       "                    \"curveness\": 0,\n",
       "                    \"type\": \"solid\"\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    ],\n",
       "    \"title\": [\n",
       "        {\n",
       "            \"text\": \"\\u884c\\u4e3a\\u8bc4\\u5206\\u5361\\u6a21\\u578b\\u8868\\u73b0\"\n",
       "        }\n",
       "    ]\n",
       "};\n",
       "                chart_ea8e84a85e3d497f9c4a997ebd29cb82.setOption(option_ea8e84a85e3d497f9c4a997ebd29cb82);\n",
       "        });\n",
       "    </script>\n"
      ],
      "text/plain": [
       "<pyecharts.render.display.HTML at 0x1a158fabe0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyecharts.charts import *\n",
    "from pyecharts import options as opts\n",
    "\n",
    "from pylab import *\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option('display.unicode.ambiguous_as_wide', True)\n",
    "pd.set_option('display.unicode.east_asian_width', True)\n",
    "line = (\n",
    "\n",
    "    Line()\n",
    "    .add_xaxis(list(val_repot.index))\n",
    "    .add_yaxis(\n",
    "        \"分组坏人占比\",\n",
    "        list(val_repot.BADRATE),\n",
    "        yaxis_index=0,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(title=\"行为评分卡模型表现\"),\n",
    "    )\n",
    "    .extend_axis(\n",
    "        yaxis=opts.AxisOpts(\n",
    "            name=\"累计坏人占比\",\n",
    "            type_=\"value\",\n",
    "            min_=0,\n",
    "            max_=0.5,\n",
    "            position=\"right\",\n",
    "            axisline_opts=opts.AxisLineOpts(\n",
    "                linestyle_opts=opts.LineStyleOpts(color=\"red\")\n",
    "            ),\n",
    "            axislabel_opts=opts.LabelOpts(formatter=\"{value}\"),\n",
    "        )\n",
    "\n",
    "    )\n",
    "    .add_xaxis(list(val_repot.index))\n",
    "    .add_yaxis(\n",
    "        \"KS\",\n",
    "        list(val_repot['KS']),\n",
    "        yaxis_index=1,\n",
    "        color=\"blue\",\n",
    "        label_opts=opts.LabelOpts(is_show=False),\n",
    "    )\n",
    ")\n",
    "line.render_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
